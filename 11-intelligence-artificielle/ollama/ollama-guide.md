# üéì Guide D√©butant - Ollama : Votre ChatGPT Personnel sur Raspberry Pi

> **Pour qui ?** Toute personne curieuse de l'IA, souhaitant avoir son propre assistant intelligent priv√©, ou voulant exp√©rimenter avec les mod√®les de langage sans frais.
> **Dur√©e de lecture** : 15 minutes
> **Niveau** : D√©butant

---

## ü§î C'est quoi Ollama ?

### En une phrase
**Ollama est un outil qui installe et fait fonctionner des intelligences artificielles comme ChatGPT directement sur votre Raspberry Pi, de mani√®re 100% priv√©e et gratuite.**

### Analogie simple

Imaginez que les grands mod√®les d'IA (comme ceux de Google, OpenAI, etc.) sont des **chefs cuisiniers √©toil√©s** qui travaillent dans des restaurants tr√®s chers et lointains (le cloud).

**Ollama**, c'est comme si vous aviez un de ces chefs √©toil√©s qui venait cuisiner **directement dans votre cuisine** (votre Raspberry Pi). 

-   **C'est priv√©** : Personne ne sait ce que vous lui demandez de cuisiner.
-   **C'est gratuit** : Une fois le chef install√©, vous pouvez lui demander autant de plats que vous voulez.
-   **C'est personnalisable** : Vous pouvez choisir votre chef (Llama 3, Mistral, Phi-3) et m√™me lui apprendre de nouvelles recettes.

L'interface **Open WebUI** est le **menu interactif** qui vous permet de parler facilement avec votre chef cuisinier.

---

## üéØ Pourquoi est-ce si puissant ?

-   **Confidentialit√© absolue** : Posez des questions sur des sujets sensibles, personnels ou professionnels, sans craindre que vos donn√©es soient utilis√©es pour entra√Æner de futurs mod√®les ou lues par une entreprise.
-   **Pas de facture surprise** : Exp√©rimentez, posez des milliers de questions, g√©n√©rez des textes longs... C'est illimit√© et gratuit.
-   **Fonctionne sans Internet** : Une fois un mod√®le t√©l√©charg√©, vous pouvez utiliser votre IA m√™me si votre connexion internet est coup√©e.
-   **Explorez des mod√®les vari√©s** : Acc√©dez √† une immense biblioth√®que de mod√®les open-source, chacun avec sa propre personnalit√© et ses propres forces (cr√©ativit√©, codage, concision, etc.).

---

## üöÄ Premiers Pas avec Open WebUI

Apr√®s l'installation, vous acc√©dez √† une interface de chat qui ressemble beaucoup √† ChatGPT.

### 1. S√©lectionner un Mod√®le

En haut de l'interface, vous pouvez voir le mod√®le actuellement charg√© (par d√©faut, `phi3:3.8b`). Si vous avez t√©l√©charg√© d'autres mod√®les, vous pouvez basculer entre eux ici.

### 2. D√©marrer une Conversation

C'est aussi simple que d'utiliser n'importe quel autre chatbot. Tapez votre question dans la zone de texte et appuyez sur Entr√©e.

**Id√©es de prompts pour commencer :**
-   `Explique-moi le concept de la blockchain comme si j'avais 10 ans.`
-   `√âcris-moi un email professionnel pour demander une augmentation.`
-   `Donne-moi une recette de cuisine simple et rapide pour ce soir avec des p√¢tes, des tomates et du fromage.`
-   `Cr√©e un script Python qui renomme tous les fichiers d'un dossier.`

### 3. Cr√©er des "Personas"

Vous pouvez cr√©er des assistants sp√©cialis√©s. Par exemple, un "Expert en Marketing" ou un "Professeur d'Histoire".

1.  Cliquez sur votre profil en haut √† droite ‚Üí **Settings**.
2.  Allez dans **Prompts**.
3.  Cr√©ez un nouveau prompt avec un message syst√®me comme : `"Tu es un expert en marketing digital. Tes r√©ponses doivent √™tre concises, strat√©giques et orient√©es r√©sultats."`
4.  Maintenant, vous pouvez d√©marrer de nouvelles conversations avec cette personnalit√©.

---

## üß† G√©rer les Mod√®les avec Ollama

La gestion des mod√®les se fait en ligne de commande, via SSH sur votre Pi.

### Lister les Mod√®les Install√©s

```bash
docker exec ollama ollama list
```
Cette commande vous montrera tous les mod√®les que vous avez t√©l√©charg√©s et l'espace qu'ils occupent.

### T√©l√©charger un Nouveau Mod√®le

1.  Allez sur la [biblioth√®que de mod√®les Ollama](https://ollama.com/library) pour voir ce qui est disponible.
2.  Choisissez un mod√®le qui vous int√©resse. Les plus populaires sont souvent les meilleurs pour commencer (ex: `llama3`, `mistral`).
3.  Copiez le nom du mod√®le (ex: `llama3:8b`).
4.  Sur votre Pi, lancez la commande :

```bash
docker exec ollama ollama pull llama3:8b
```

Le t√©l√©chargement peut prendre du temps et de l'espace disque (plusieurs Gigaoctets).

### Discuter avec un Mod√®le en Ligne de Commande

Pour un test rapide sans passer par l'interface web :

```bash
docker exec -it ollama ollama run llama3:8b
```
Vous entrerez dans un mode de chat interactif directement dans votre terminal.

### Supprimer un Mod√®le

Si vous manquez d'espace, vous pouvez supprimer les mod√®les que vous n'utilisez pas :

```bash
docker exec ollama ollama rm nom-du-modele
```

---

## üí° Astuces et Bonnes Pratiques

-   **Commencez petit** : Les mod√®les existent en plusieurs tailles (ex: 7 milliards de param√®tres, 70 milliards...). Les plus petits sont plus rapides mais moins "intelligents". Pour le Raspberry Pi 5, les mod√®les entre 3 et 8 milliards de param√®tres (`3b` √† `8b`) sont un bon compromis.
-   **Soyez pr√©cis dans vos prompts** : Plus votre question est d√©taill√©e, meilleure sera la r√©ponse. Donnez du contexte, un format de sortie attendu, etc.
-   **Utilisez l'API** : La vraie puissance d'Ollama est son API. Vous pouvez l'appeler depuis vos propres scripts ou d'autres applications (comme n8n) pour automatiser des t√¢ches complexes.

---

F√©licitations ! Vous avez maintenant votre propre IA priv√©e, pr√™te √† r√©pondre √† toutes vos questions, √† vous aider √† √©crire, √† coder, et bien plus encore. Le champ des possibles est immense.
