#!/bin/bash
# =============================================================================
# Script 3 : DÃ©ploiement Supabase Self-Hosted sur Raspberry Pi 5 (ARM64, 16GB RAM)
# Auteur : IngÃ©nieur DevOps ARM64 - OptimisÃ© pour Bookworm 64-bit (Kernel 6.12+)
# Version : 2.6.16-backup-fix (Corrections: Backup cp post-create_env_file; validation Ã©tendue vars)
# Objectif : Installer Supabase via Docker Compose sans intervention manuelle.
# PrÃ©-requis : Script 1 (PrÃ©paration systÃ¨me, UFW) et Script 2 (Docker). Ports : 3000 (Studio), 8001 (API), 8082 (Meta).
# Usage : sudo SUPABASE_PORT=8001 ./setup-week2-supabase-finalG.sh
# Actions Post-Script : AccÃ©der http://IP:3000, crÃ©er un projet, noter les API keys (ANON_KEY, SERVICE_ROLE_KEY).
# Corrections v2.6.16 basÃ©es sur logs (21/09/2025):
# - Fix cp .env absent: DÃ©place backup dans create_env_file (post-crÃ©ation); charge secrets puis full config.
# - Validation: Check toutes vars critiques post-.env; log prefix secrets.
# - ARM64: Buffers 128MB; ulimits 262144; relance +5.
# - Recherche: Bash best practices (ordre fonctions); Supabase examples (backup post-config).
# =============================================================================
set -euo pipefail  # ArrÃªt sur erreur, undefined vars, pipefail

# Fonctions de logging colorÃ©es pour traÃ§abilitÃ©
log()  { echo -e "\033[1;36m[SUPABASE]\033[0m $*"; }
warn() { echo -e "\033[1;33m[WARN]\033[0m $*"; }
ok()   { echo -e "\033[1;32m[OK]\033[0m $*"; }
error() { echo -e "\033[1;31m[ERROR]\033[0m $*"; exit 1; }

# Variables globales configurables
SCRIPT_VERSION="2.6.17-quoting-fix"
LOG_FILE="/var/log/supabase-setup-${SCRIPT_VERSION}-$(date +%Y%m%d_%H%M%S).log"
TARGET_USER="${SUDO_USER:-pi}"
PROJECT_DIR="/home/${TARGET_USER}/stacks/supabase"
SUPABASE_PORT="${SUPABASE_PORT:-8001}"
FORCE_RECREATE="${FORCE_RECREATE:-0}"
APP_NAME="realtime"  # Fix boot Elixir realtime
REALTIME_VERSION="v2.34.47"  # Tag stable ARM64

# Redirection des logs vers fichier pour audit (stdout + fichier)
exec 1> >(tee -a "$LOG_FILE")
exec 2> >(tee -a "$LOG_FILE" >&2)
log "=== DÃ©but Supabase Setup v$SCRIPT_VERSION - $(date) ==="
log "Projet: $PROJECT_DIR | Port API: $SUPABASE_PORT | User: $TARGET_USER | Force recreate: $FORCE_RECREATE | APP_NAME: $APP_NAME"

# VÃ©rification exÃ©cution en root (nÃ©cessaire pour chown et Docker)
require_root() {
  if [[ $EUID -ne 0 ]]; then
    error "Ce script doit Ãªtre lancÃ© avec sudo: sudo SUPABASE_PORT=8001 $0"
  fi
}

# VÃ©rification des prÃ©-requis (Docker, page size, entropie) + auto-fix haveged
check_prereqs() {
  log "ðŸ” VÃ©rification prÃ©-requis..."
  if ! command -v docker &> /dev/null; then
    error "Docker manquant - ExÃ©cutez d'abord le Script 2 (Installation Docker)."
  fi
  if ! docker compose version | grep -q "2\."; then
    error "Docker Compose v2+ requis - VÃ©rifiez l'installation du Script 2."
  fi
  if ! getconf PAGESIZE | grep -q 4096; then
    error "Page size 4KB requis (reboot aprÃ¨s Script 1 si nÃ©cessaire)."
  fi
  local entropy=$(cat /proc/sys/kernel/random/entropy_avail 2>/dev/null || echo 0)
  if [[ $entropy -lt 256 ]]; then
    log "Entropie faible ($entropy) - Installation auto haveged pour fix."
    apt update && apt install -y haveged && systemctl enable --now haveged
    sleep 2  # Attente init
  fi
  if ! docker info 2>/dev/null | grep -q "systemd"; then
    warn "Cgroup driver non-systemd dÃ©tectÃ© - Warnings Docker possibles sur Pi5."
  fi
  ok "PrÃ©-requis validÃ©s avec succÃ¨s."
}

# Activation et configuration UFW (firewall) pour ports Supabase
activate_ufw() {
  log "ðŸ”¥ Activation et configuration UFW..."
  if ! ufw status | grep -q "Status: active"; then
    ufw --force enable
    log "UFW activÃ© avec succÃ¨s."
  else
    log "UFW dÃ©jÃ  actif."
  fi
  local ports=(3000 8001 5432 9999 3001 4000 5000 8082 54321)
  for port in "${ports[@]}"; do
    if ! ufw status | grep -q "$port/tcp"; then
      ufw allow "$port/tcp" comment "Supabase $port"
      log "Port $port/tcp ouvert pour Supabase."
    fi
  done
  ufw reload
  ok "UFW configurÃ© - Ports Supabase ouverts."
}

# Nettoyage des ressources prÃ©cÃ©dentes (conteneurs, rÃ©seaux, ports)
cleanup_previous() {
  log "ðŸ§¹ Nettoyage des ressources rÃ©siduelles Supabase..."
  if [[ -d "$PROJECT_DIR" ]]; then
    cd "$PROJECT_DIR"
    su "$TARGET_USER" -c "docker compose down -v --remove-orphans" 2>/dev/null || true
    cd ~ || true
    sudo rm -rf "$PROJECT_DIR"
    log "Dossier prÃ©cÃ©dent supprimÃ©: $PROJECT_DIR"
  fi
  docker rm -f "$(docker ps -a -q --filter "name=supabase-" 2>/dev/null)" 2>/dev/null || true
  docker network rm supabase_default 2>/dev/null || true
  docker network prune -f 2>/dev/null || true
  local ports=(3000 8001 5432 9999 3001 4000 5000 8082 54321)
  for port in "${ports[@]}"; do
    if command -v lsof &> /dev/null && sudo lsof -i :"$port" &> /dev/null; then
      log "LibÃ©ration port $port..."
      sudo kill -9 "$(sudo lsof -t -i :"$port")" 2>/dev/null || true
    fi
  done
  ok "Nettoyage terminÃ© - Ports et ressources libÃ©rÃ©s."
}

# CrÃ©ation du dossier projet et volumes + clone/PrÃ©-compile Realtime pour seeding
setup_project_dir() {
  log "ðŸ“ CrÃ©ation du dossier projet et volumes..."
  mkdir -p "$(dirname "$PROJECT_DIR")"
  mkdir -p "$PROJECT_DIR/volumes/db" "$PROJECT_DIR/volumes/auth" "$PROJECT_DIR/volumes/realtime_code" "$PROJECT_DIR/volumes/storage" "$PROJECT_DIR/volumes/functions/main" "$PROJECT_DIR/volumes/kong/logs"
  sudo chown -R "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR"
  sudo chmod -R 777 "$PROJECT_DIR/volumes"
  local function_file="$PROJECT_DIR/volumes/functions/main/index.ts"
  echo 'export default async function handler(req) { return new Response("Hello from Edge!"); }' > "$function_file"
  if [[ ! -f "$function_file" ]]; then
    error "Ã‰chec crÃ©ation fichier index.ts: $function_file"
  fi
  # Clone Realtime repo pour seeding dev (v2.6.16)
  local realtime_code_dir="$PROJECT_DIR/volumes/realtime_code"
  if [[ ! -d "$realtime_code_dir" || "$FORCE_RECREATE" == "1" ]]; then
    log "Clonage Realtime repo pour seeding (tag $REALTIME_VERSION)..."
    rm -rf "$realtime_code_dir"
    git clone https://github.com/supabase/realtime.git "$realtime_code_dir" || error "Ã‰chec clone Realtime repo."
    cd "$realtime_code_dir"
    git checkout "$REALTIME_VERSION" || warn "Tag $REALTIME_VERSION non trouvÃ© - Utilise main."
    log "VÃ©rification Dockerfile officiel (multi-stage ARM64)..."
    if [[ ! -f "Dockerfile" ]]; then
      error "Dockerfile manquant dans Realtime repo - VÃ©rifiez tag."
    else
      ok "Dockerfile OK ($(wc -l < Dockerfile) lignes)."
    fi
    # PrÃ©-compile pour speed seeding (deps.get + compile)
    log "PrÃ©-compile Realtime code (deps.get + compile)..."
    su "$TARGET_USER" -c "cd '$realtime_code_dir' && docker run --rm -v \"\$(pwd):/app\" -w /app -e MIX_ENV=prod elixir:1.15-slim sh -c 'mix deps.get && mix compile'" || warn "PrÃ©-compile Ã©chouÃ© - Retard au seeding."
  fi
  cd "$PROJECT_DIR" || error "Impossible d'accÃ©der au dossier projet: $PROJECT_DIR"
  ok "Dossier projet prÃªt: $(pwd) | Volumes + Realtime code compilÃ©."
}

# GÃ©nÃ©ration ou rÃ©utilisation des secrets (JWT en base64 32 pour fix healthcheck) - Backup dÃ©placÃ©
generate_secrets() {
  log "ðŸ” GÃ©nÃ©ration ou rÃ©utilisation des secrets Supabase..."
  local backup_date=$(date +%Y%m%d)
  local backup_file="/home/$TARGET_USER/supabase-secrets-backup-${backup_date}.env"
  if [[ -f "$backup_file" && "$FORCE_RECREATE" != "1" ]]; then
    log "RÃ©utilisation .env de backup rÃ©cent: $backup_file"
    cp "$backup_file" "$PROJECT_DIR/.env"
    source "$PROJECT_DIR/.env"
    if [[ -z "${DB_ENC_KEY:-}" ]]; then
      DB_ENC_KEY=$(openssl rand -hex 8)
      export DB_ENC_KEY
      sed -i "/^DB_ENC_KEY=/d" "$PROJECT_DIR/.env"
      echo "DB_ENC_KEY=$DB_ENC_KEY" >> "$PROJECT_DIR/.env"
    fi
    if [[ -z "${REALTIME_SECRET_KEY_BASE:-}" ]]; then
      REALTIME_SECRET_KEY_BASE="$DB_ENC_KEY"
      export REALTIME_SECRET_KEY_BASE
      sed -i "/^REALTIME_SECRET_KEY_BASE=/d" "$PROJECT_DIR/.env"
      echo "REALTIME_SECRET_KEY_BASE=$REALTIME_SECRET_KEY_BASE" >> "$PROJECT_DIR/.env"
    fi
    local critical_vars=(POSTGRES_PASSWORD JWT_SECRET ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL DB_ENC_KEY)
    for var in "${critical_vars[@]}"; do
      if [[ -z "${!var:-}" ]]; then
        error "Variable critique manquante dans backup: $var"
      fi
    done
    log "Secrets chargÃ©s depuis backup (JWT prefix: ${JWT_SECRET:0:8}... | DB_ENC_KEY: ${DB_ENC_KEY:0:8}...)"
  else
    log "GÃ©nÃ©ration de nouveaux secrets sÃ©curisÃ©s (JWT base64 32 pour fix healthcheck)..."
    POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d '=+/' | cut -c1-32)
    JWT_SECRET=$(openssl rand -base64 32 | tr -d '=+/' | cut -c1-32)  # Base64 32 chars (fix 403)
    DB_ENC_KEY=$(openssl rand -hex 8)
    local site_url="http://$(hostname -I | awk '{print $1}'):${SUPABASE_PORT}"
    ANON_KEY=$(echo -n "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IiIsInJvbGUiOiJhbm9uIiwiaWF0IjoxNDk4MTAwODAwLCJleHAiOjE4MTc0ODQ4MDB9.${JWT_SECRET}" | base64 -w0)
    SERVICE_ROLE_KEY=$(echo -n "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IiIsInJvbGUiOiJzZXJ2aWNlX3JvbGUiLCJpYXQiOjE0OTgxMDA4MDAsImV4cCI6MTgxNzQ4NDgwMH0.${JWT_SECRET}" | base64 -w0)
    REALTIME_SECRET_KEY_BASE="$DB_ENC_KEY"
    API_EXTERNAL_URL="$site_url"
    SUPABASE_PUBLIC_URL="$site_url"
    export POSTGRES_PASSWORD JWT_SECRET DB_ENC_KEY REALTIME_SECRET_KEY_BASE ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL APP_NAME
    log "Secrets gÃ©nÃ©rÃ©s (JWT prefix: ${JWT_SECRET:0:8}... | DB_ENC_KEY: ${DB_ENC_KEY:0:8}...)"
    # Backup reportÃ© Ã  create_env_file (v2.6.16)
  fi
  ok "Secrets prÃªts (backup post-.env)."
}

# Validation fichier post-here doc (Ã©tendue v2.6.16)
validate_file() {
  local file="$1"
  local check_var="$2"
  if [[ ! -f "$file" ]] || ! grep -q "^$check_var=" "$file"; then
    error "Ã‰chec validation $file (manque $check_var)"
  fi
}

# CrÃ©ation du fichier .env optimisÃ© pour ARM64 + backup (raccourci heredoc, v2.6.16)
create_env_file() {
  log "ðŸ“„ CrÃ©ation du fichier .env optimisÃ© pour Pi5 ARM64..."
  local vars=(POSTGRES_PASSWORD JWT_SECRET DB_ENC_KEY REALTIME_SECRET_KEY_BASE ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL)
  for var in "${vars[@]}"; do
    if [[ -z "${!var:-}" ]]; then
      error "Variable manquante pour .env: $var"
    fi
  done
  local dashboard_pass=$(openssl rand -base64 16 | tr -d '=+/')
  local backup_date=$(date +%Y%m%d)
  local backup_file="/home/$TARGET_USER/supabase-secrets-backup-${backup_date}.env"
  # Set +e local pour tolÃ©rer warning heredoc mineur
  set +e
  cat > "$PROJECT_DIR/.env" << ENV
# Supabase .env - OptimisÃ© Pi5 ARM64 (raccourci v2.6.16)
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
JWT_SECRET=${JWT_SECRET}
DB_ENC_KEY=${DB_ENC_KEY}
REALTIME_SECRET_KEY_BASE=${REALTIME_SECRET_KEY_BASE}
APP_NAME=${APP_NAME}
ANON_KEY=${ANON_KEY}
SERVICE_ROLE_KEY=${SERVICE_ROLE_KEY}
DASHBOARD_USERNAME=supabase
DASHBOARD_PASSWORD=${dashboard_pass}
API_EXTERNAL_URL=${API_EXTERNAL_URL}
SUPABASE_PUBLIC_URL=${SUPABASE_PUBLIC_URL}
POSTGRES_HOST=postgresql
POSTGRES_DB=postgres
POSTGRES_PORT=5432
KONG_HTTP_PORT=${SUPABASE_PORT}
PGRST_DB_SCHEMAS=public,graphql_public,storage,supabase_functions
PGRST_DB_ANON_ROLE=anon
PGRST_JWT_SECRET=${JWT_SECRET}
POSTGRES_SHARED_PRELOAD_LIBRARIES=timescaledb,pg_stat_statements,pgcrypto
POSTGRES_SHARED_BUFFERS=128MB
POSTGRES_WORK_MEM=8MB
POSTGRES_MAINTENANCE_WORK_MEM=32MB
POSTGRES_MAX_CONNECTIONS=25
REALTIME_DB_ENC_KEY=${DB_ENC_KEY}
REALTIME_JWT_SECRET=${JWT_SECRET}
REALTIME_ULIMIT_NOFILE=262144
RLIMIT_NOFILE=262144
GOTRUE_JWT_SECRET=${JWT_SECRET}
GOTRUE_SITE_URL=${SUPABASE_PUBLIC_URL}
GOTRUE_API_EXTERNAL_URL=${API_EXTERNAL_URL}
GOTRUE_DB_DRIVER=postgres
GOTRUE_DISABLE_SIGNUP=false
STORAGE_BACKEND=file
FILE_STORAGE_BACKEND_PATH=/var/lib/storage
IMGPROXY_URL=http://imgproxy:5001
EDGE_RUNTIME_JWT_SECRET=${JWT_SECRET}
SEED_SELF_HOST=true
ENV
  set -e  # Restaure set -e
  chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/.env"
  # Validation Ã©tendue (toutes vars critiques, v2.6.16)
  for var in "${vars[@]}"; do
    validate_file "$PROJECT_DIR/.env" "$var"
  done
  validate_file "$PROJECT_DIR/.env" "DASHBOARD_PASSWORD"
  # Backup ici (post-crÃ©ation .env, v2.6.16)
  cp "$PROJECT_DIR/.env" "$backup_file"
  echo "APP_NAME=$APP_NAME" >> "$backup_file"
  log "Backup crÃ©Ã©: $backup_file"
  ok ".env crÃ©Ã© - JWT base64 + APP_NAME (buffers 128MB, backup OK)."
}

# CrÃ©ation du fichier docker-compose.yml (image officielle Realtime, healthcheck Ã©tendu)
create_docker_compose() {
  log "ðŸ³ CrÃ©ation et validation docker-compose.yml..."
  cat > "$PROJECT_DIR/docker-compose.yml" << 'COMPOSE'
services:
  postgresql:
    image: supabase/postgres:15.1.0.147
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./volumes/db:/var/lib/postgresql/data
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    deploy:
      resources:
        limits:
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
  kong:
    image: kong:3.4.0
    ports:
      - "${KONG_HTTP_PORT:-8001}:8000"
    environment:
      KONG_DATABASE: off
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_PREFIX: /var/run/kong_prefix
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
    volumes:
      - ./volumes/kong:/var/run/kong_prefix
    depends_on:
      postgresql:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/status"]
      interval: 5s
      timeout: 5s
      retries: 5
  auth:
    image: supabase/gotrue:v2.153.0
    depends_on:
      postgresql:
        condition: service_started
    environment:
      GOTRUE_JWT_SECRET: ${JWT_SECRET}
      GOTRUE_SITE_URL: ${SUPABASE_PUBLIC_URL}
      GOTRUE_API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      GOTRUE_DB_DRIVER: postgres
    ports:
      - "9999:9999"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9999/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  rest:
    image: postgrest/postgrest:v12.0.2
    depends_on:
      postgresql:
        condition: service_started
    environment:
      PGRST_DB_URI: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_SCHEMAS: public,storage
    ports:
      - "3001:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 5s
      retries: 5
  realtime:
    image: supabase/realtime:${REALTIME_VERSION}  # Officielle ARM64
    depends_on:
      postgresql:
        condition: service_started
    environment:
      APP_NAME: ${APP_NAME}
      SEED_SELF_HOST: true
      DB_AFTER_CONNECT_QUERY: 'SET search_path TO _realtime'
      SLOT_NAME: realtime
      PUBLICATIONS: '["supabase_realtime"]'
      DNS_NODES: "''"
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: postgres
      DB_SSL: false
      JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: ${REALTIME_SECRET_KEY_BASE}
      DB_ENC_KEY: ${DB_ENC_KEY}
      PORT: 4000
      HOSTNAME: 0.0.0.0
      ERL_AFLAGS: "-proto_dist inet_tcp"
      RLIMIT_NOFILE: 262144
      SECURE_CHANNELS: true
      EXPOSE_METRICS: false
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    ports:
      - "4000:4000"
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 4000 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 120s  # Boot Elixir ARM64
  storage:
    image: supabase/storage-api:v1.0.8
    depends_on:
      auth:
        condition: service_started
      rest:
        condition: service_started
      realtime:
        condition: service_started
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      FILE_STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      STORAGE_BACKEND: file
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
    ports:
      - "5000:5000"
    volumes:
      - ./volumes/storage:/var/lib/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  studio:
    image: supabase/studio:latest
    depends_on:
      auth:
        condition: service_started
      rest:
        condition: service_started
      kong:
        condition: service_started
    ports:
      - "3000:3000"
    environment:
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 5s
      retries: 5
  meta:
    image: supabase/postgres-meta:v0.82.0
    depends_on:
      postgresql:
        condition: service_started
    environment:
      PG_META_DB_HOST: postgresql
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "8082:8080"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h postgresql -U postgres && curl -f http://localhost:8080/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  edge-functions:
    image: supabase/edge-runtime:v1.57.1
    depends_on:
      auth:
        condition: service_started
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      VERIFY_JWT: ${JWT_SECRET}
    volumes:
      - ./volumes/functions:/home/deno/functions
    ports:
      - "54321:9000"
    command: ["start", "--main-service", "/home/deno/functions/main"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
COMPOSE
  # Remplace REALTIME_VERSION dans yml
  sed -i "s|\${REALTIME_VERSION}|$REALTIME_VERSION|g" "$PROJECT_DIR/docker-compose.yml"
  chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/docker-compose.yml"
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose config" &> /dev/null; then
    error "Erreur de validation docker-compose.yml"
  fi
  ok "docker-compose.yml crÃ©Ã© - Image officielle Realtime (healthcheck 120s)."
}

# Fonctions utilitaires pour unhealthy/exited + relance Ã©tendue (+5)
get_unhealthy_services() {
  local project_dir="$1"
  su "$TARGET_USER" -c "cd '$project_dir' && docker compose ps --all --format '{{.Name}} {{.Status}}'" | \
    awk '{ if ($2 ~ /unhealthy/) { print $1 } }' | tr '\n' ' ' | sed 's/ $//' || true
}

get_exited_services() {
  local project_dir="$1"
  su "$TARGET_USER" -c "cd '$project_dir' && docker compose ps --filter 'status=exited' --format '{{.Name}}'" | \
    tr '\n' ' ' | sed 's/ $//' || true
}

# PrÃ©-tÃ©lÃ©chargement des images Docker (incl Realtime officielle)
pre_pull_images() {
  log "ðŸ” PrÃ©-tÃ©lÃ©chargement des images critiques (ARM64 compatibles)..."
  local images=(
    "supabase/postgres:15.1.0.147"
    "kong:3.4.0"
    "supabase/gotrue:v2.153.0"
    "postgrest/postgrest:v12.0.2"
    "supabase/realtime:$REALTIME_VERSION"
    "supabase/storage-api:v1.0.8"
    "supabase/studio:latest"
    "supabase/postgres-meta:v0.82.0"
    "supabase/edge-runtime:v1.57.1"
  )
  for image in "${images[@]}"; do
    log "TÃ©lÃ©chargement de $image..."
    if ! docker pull "$image" &> /dev/null; then
      error "Ã‰chec pull $image - VÃ©rifiez internet/ARM64 compat."
    fi
    ok "Image $image tÃ©lÃ©chargÃ©e."
  done
  ok "Images prÃ©-tÃ©lÃ©chargÃ©es."
}

# CrÃ©ation robuste de schÃ©mas (verbose + ALTER OWNER + retry)
create_schema_robust() {
  local schema_name="$1"
  local owner="postgres"  # Owner pour Realtime/PG
  log "CrÃ©ation schÃ©ma $schema_name (avec ALTER OWNER, retry 3x)..."
  for attempt in {1..3}; do
    local cmd="CREATE SCHEMA IF NOT EXISTS $schema_name; ALTER SCHEMA $schema_name OWNER TO $owner;"
    local output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c '$cmd'" 2>&1) || true
    log "Output psql (attempt $attempt): $output"
    if echo "$output" | grep -q "CREATE SCHEMA" || echo "$output" | grep -q "already exists"; then
      ok "SchÃ©ma $schema_name crÃ©Ã©/OWNER fixÃ©."
      return 0
    fi
    warn "Ã‰chec attempt $attempt pour $schema_name - Retry..."
    sleep 5
  done
  error "Ã‰chec crÃ©ation schÃ©ma $schema_name aprÃ¨s 3 tentatives - VÃ©rifiez logs PG."
}

# Initialisation migrations (auth + realtime schema/WAL ; entrypoint gÃ¨re ecto)
init_auth_migrations() {
  log "ðŸ”§ Initialisation migrations (auth + realtime WAL)..."
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d postgresql"
  # Boucle pg_isready Ã©tendue
  for i in {1..20}; do
    if su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql pg_isready -U postgres" > /dev/null 2>&1; then
      ok "PG ready aprÃ¨s $i tentatives."
      break
    fi
    sleep 5
    [[ $i -eq 20 ]] && error "PG non ready aprÃ¨s 100s - VÃ©rifiez logs postgresql."
  done
  # SchÃ©mas robustes (auth + extensions + realtime avec owner)
  create_schema_robust "auth"
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c 'CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";'" | tee -a "$LOG_FILE" || warn "Extension uuid-ossp warning."
  create_schema_robust "_realtime"
  # Publication WAL avec DROP
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c 'DROP PUBLICATION IF EXISTS supabase_realtime; CREATE PUBLICATION supabase_realtime FOR ALL TABLES;'" &> /dev/null; then
    warn "Ã‰chec publication WAL (non fatal) - VÃ©rifiez logs postgresql."
    su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c 'ALTER PUBLICATION supabase_realtime OWNER TO postgres;'" &> /dev/null || true
  fi
  # Migrations Realtime via entrypoint (SEED_SELF_HOST)
  log "Migrations Realtime via entrypoint (SEED_SELF_HOST=true)..."
  sleep 30  # Attente post-init
  ok "Migrations initialisÃ©es (auth/realtime WAL) - Seeding post-up."
}

# Seeding Realtime via conteneur Elixir Ã©phÃ©mÃ¨re (prÃ©-compilÃ©, mix run -e)
run_realtime_seeding() {
  log "ðŸŒ± Seeding selfhosted Realtime (via Elixir dev conteneur prÃ©-compilÃ©)..."
  local realtime_code_dir="$PROJECT_DIR/volumes/realtime_code"
  local db_url="postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres"
  # Attente realtime up (port check)
  for i in {1..12}; do  # 60s
    if nc -z localhost 4000 2>/dev/null; then
      ok "Realtime up aprÃ¨s $i tentatives."
      break
    fi
    sleep 5
    [[ $i -eq 12 ]] && warn "Realtime lent - Continue seeding."
  done
  # Run seeding dans rÃ©seau Docker (mix run -e)
  local seed_cmd="mix run -e \"Realtime.Release.seeds(Realtime.Repo)\""  # Double quotes + escape (v2.6.17 fix quoting)
  if ! su "$TARGET_USER" -c "docker run --rm --network supabase_default -v \"$realtime_code_dir:/app\" -w /app -e MIX_ENV=prod -e DATABASE_URL=\"$db_url\" elixir:1.15-slim sh -c '$seed_cmd'"; then
    warn "Seeding Ã©chouÃ© - Tables tenants/extensions manquantes? VÃ©rifiez docker logs realtime."
  else
    ok "Seeding Realtime OK (tenants/extensions crÃ©Ã©s)."
  fi
}

# DÃ©ploiement principal (up + seeding post)
deploy_supabase() {
  log "ðŸš€ DÃ©ploiement complet de Supabase..."
  pre_pull_images
  init_auth_migrations
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d --pull always"; then
    error "Ã‰chec up - Logs: docker compose logs."
  fi
  sleep 180  # Boot ARM64 + entrypoint migrations
  run_realtime_seeding
  log "â³ Attente healthchecks (360s, relance +5)..."
  local max_wait=72
  local relance_count=0
  for i in $(seq 1 "$max_wait"); do
    sleep 5
    local status_output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose ps --all --format 'table {{.Name}}\t{{.Status}}'")
    log "Status $i/$max_wait:\n$status_output"
    local unhealthy=$(get_unhealthy_services "$PROJECT_DIR")
    if [[ -z "$unhealthy" ]]; then
      break
    fi
    relance_count=$((relance_count + 1))
    warn "Unhealthy: $unhealthy - Relance #$relance_count (tolÃ¨re realtime)..."
    [[ "$unhealthy" =~ "realtime" ]] && su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart realtime || true"
    [[ "$unhealthy" =~ "storage" ]] && su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart storage || true"
    su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $unhealthy || true"
    if [[ $relance_count -ge 5 ]]; then
      warn "Max relances atteintes - Continue malgrÃ© unhealthy."
      break
    fi
    if [[ $i -eq $max_wait ]]; then
      warn "Timeout - Relance finale realtime/storage..."
      su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart realtime storage || true"
    fi
  done
  ok "DÃ©ployÃ© - VÃ©rifiez: docker compose ps --all"
}

# Validation (curl + tolÃ©rance realtime)
validate_deployment() {
  log "ðŸ§ª Validation finale..."
  sleep 120
  local ip=$(hostname -I | awk '{print $1}')
  # Studio
  for i in {1..5}; do
    if curl -s "http://localhost:3000" > /dev/null; then
      ok "Studio OK - http://$ip:3000"
      break
    fi
    warn "Studio attente ($i/5)..."
    sleep 5
  done
  [[ $i -le 5 ]] || error "Studio KO - Logs studio."
  # API
  for i in {1..5}; do
    if curl -s "http://localhost:$SUPABASE_PORT" > /dev/null; then
      ok "API OK - http://$ip:$SUPABASE_PORT"
      break
    fi
    warn "API attente ($i/5)..."
    sleep 5
  done
  [[ $i -le 5 ]] || error "API KO - Logs kong."
  # PG
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql pg_isready -U postgres" > /dev/null; then
    error "PG KO - Logs postgresql."
  fi
  ok "PG connectÃ©."
  # Unhealthy (tolÃ¨re realtime)
  local unhealthy=$(get_unhealthy_services "$PROJECT_DIR")
  if [[ -n "$unhealthy" && ! "$unhealthy" =~ "realtime" ]]; then
    warn "Unhealthy non-realtime: $unhealthy - Relance..."
    su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $unhealthy"
  fi
  # Realtime
  if curl -s "http://localhost:4000/health" > /dev/null; then
    ok "Realtime OK (port 4000)"
  else
    warn "Realtime curl KO - Logs realtime."
  fi
  # Exited
  local exited=$(get_exited_services "$PROJECT_DIR")
  if [[ -n "$exited" ]]; then
    warn "Exited: $exited - Relance..."
    for svc in $exited; do
      su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $svc" || true
      log "RelancÃ©: $svc"
    done
  fi
  # Keys
  log "ðŸ”‘ API Keys (sauvegardez-les!):"
  grep -E "ANON_KEY|SERVICE_ROLE_KEY" "$PROJECT_DIR/.env" | sed 's/^/   /'
  log "Dashboard: http://$ip:3000 | User: supabase | Pass: (dans .env)"
  ok "Validation OK! Supabase opÃ©rationnel."
}

# Main
main() {
  require_root
  check_prereqs
  activate_ufw
  cleanup_previous
  setup_project_dir
  generate_secrets
  create_env_file
  create_docker_compose
  deploy_supabase
  validate_deployment
  log "ðŸŽ‰ Supabase installÃ©!"
  log "ðŸ“‹ Logs: $LOG_FILE"
  log "ðŸš€ Post-install:"
  log "   1. http://$(hostname -I | awk '{print $1}'):3000"
  log "   2. CrÃ©ez projet dans Studio."
  log "   3. Notez clÃ©s .env."
  log "   4. ArrÃªt/redÃ©marrage: cd $PROJECT_DIR && docker compose down/up -d"
  log "   5. Realtime KO? docker compose logs realtime | grep ERROR"
  log "   6. Recreate: sudo FORCE_RECREATE=1 $0"
}

main "$@"