#!/bin/bash
# =============================================================================
# Script 3 : DÃ©ploiement Supabase Self-Hosted sur Raspberry Pi 5 (ARM64, 16GB RAM)
# Auteur : IngÃ©nieur DevOps ARM64 - OptimisÃ© pour Bookworm 64-bit (Kernel 6.12+)
# Objectif : Installer Supabase via Docker Compose sans intervention manuelle.
# PrÃ©-requis : Script 1 (PrÃ©paration systÃ¨me, UFW) et Script 2 (Docker). Ports : 3000 (Studio), 8001 (API), 8082 (Meta).
# Usage : sudo SUPABASE_PORT=8001 ./setup-week2-supabase-v2.6.8.sh
# Actions Post-Script : AccÃ©der http://IP:3000, crÃ©er un projet, noter les API keys (ANON_KEY, SERVICE_ROLE_KEY).
# Corrections apportÃ©es (v2.6.8) basÃ©es sur logs fournis :
# - Fix realtime crash : Ajout APP_NAME=realtime dans env realtime (cause "RuntimeError: APP_NAME not available" en runtime.exs:78).
# - Robustesse : Ajout SEED_SELF_HOST=true pour migrations realtime ; sleep 60s post-up pour boot Elixir.
# - Parsing exited : Fix relance (vÃ©rif existence service avant restart via docker ps).
# - Validation : Test curl realtime aprÃ¨s relance ; tolÃ©rance si toujours exited (non-bloquant pour Studio).
# - Logs : Suppression doublons REALTIME_DB_ENC_KEY ; export APP_NAME global pour .env.
# =============================================================================
set -euo pipefail

# Fonctions de logging colorÃ©es pour traÃ§abilitÃ©
log()  { echo -e "\033[1;36m[SUPABASE]\033[0m $*"; }
warn() { echo -e "\033[1;33m[WARN]\033[0m $*"; }
ok()   { echo -e "\033[1;32m[OK]\033[0m $*"; }
error() { echo -e "\033[1;31m[ERROR]\033[0m $*"; exit 1; }

# Variables globales configurables
SCRIPT_VERSION="2.6.8-appname-fix"
LOG_FILE="/var/log/supabase-setup-${SCRIPT_VERSION}-$(date +%Y%m%d_%H%M%S).log"
TARGET_USER="${SUDO_USER:-pi}"
PROJECT_DIR="/home/${TARGET_USER}/stacks/supabase"
SUPABASE_PORT="${SUPABASE_PORT:-8001}"
FORCE_RECREATE="${FORCE_RECREATE:-0}"
APP_NAME="realtime"  # Nouvelle var pour fix realtime boot

# Redirection des logs vers fichier pour audit (stdout + fichier)
exec 1> >(tee -a "$LOG_FILE")
exec 2> >(tee -a "$LOG_FILE" >&2)
log "=== DÃ©but Supabase Setup v$SCRIPT_VERSION - $(date) ==="
log "Projet: $PROJECT_DIR | Port API: $SUPABASE_PORT | User: $TARGET_USER | Force recreate: $FORCE_RECREATE | APP_NAME: $APP_NAME"

# VÃ©rification exÃ©cution en root (nÃ©cessaire pour chown et Docker)
require_root() {
  if [[ $EUID -ne 0 ]]; then
    error "Ce script doit Ãªtre lancÃ© avec sudo: sudo SUPABASE_PORT=8001 $0"
  fi
}

# VÃ©rification des prÃ©-requis (Docker, page size, entropie)
check_prereqs() {
  log "ðŸ” VÃ©rification prÃ©-requis..."
  if ! command -v docker &> /dev/null; then
    error "Docker manquant - ExÃ©cutez d'abord le Script 2 (Installation Docker)."
  fi
  if ! docker compose version | grep -q "2\."; then
    error "Docker Compose v2+ requis - VÃ©rifiez l'installation du Script 2."
  fi
  if ! getconf PAGESIZE | grep -q 4096; then
    error "Page size 4KB requis (reboot aprÃ¨s Script 1 si nÃ©cessaire)."
  fi
  local entropy=$(cat /proc/sys/kernel/random/entropy_avail 2>/dev/null || echo 0)
  if [[ $entropy -lt 256 ]]; then
    warn "Entropie faible ($entropy) - Peut ralentir gÃ©nÃ©ration JWT. Installez haveged si persistant."
  fi
  if ! docker info 2>/dev/null | grep -q "systemd"; then
    warn "Cgroup driver non-systemd dÃ©tectÃ© - Warnings Docker possibles sur Pi5."
  fi
  ok "PrÃ©-requis validÃ©s avec succÃ¨s."
}

# Activation et configuration UFW (firewall) pour ports Supabase
activate_ufw() {
  log "ðŸ”¥ Activation et configuration UFW..."
  if ! ufw status | grep -q "Status: active"; then
    ufw --force enable
    log "UFW activÃ© avec succÃ¨s."
  else
    log "UFW dÃ©jÃ  actif."
  fi
  # Ports essentiels Supabase : Studio (3000), API (8001), PG (5432), Auth (9999), Realtime (4000), Storage (5000), Meta (8082), Edge (54321)
  local ports=(3000 8001 5432 9999 3001 4000 5000 8082 54321)
  for port in "${ports[@]}"; do
    if ! ufw status | grep -q "$port/tcp"; then
      ufw allow "$port/tcp" comment "Supabase $port"
      log "Port $port/tcp ouvert pour Supabase."
    fi
  done
  ufw reload
  ok "UFW configurÃ© - Ports Supabase ouverts. Statut: ufw status verbose"
}

# Nettoyage des ressources prÃ©cÃ©dentes (conteneurs, rÃ©seaux, ports)
cleanup_previous() {
  log "ðŸ§¹ Nettoyage des ressources rÃ©siduelles Supabase..."
  if [[ -d "$PROJECT_DIR" ]]; then
    cd "$PROJECT_DIR"
    # ArrÃªt et suppression volumes/orphans pour l'utilisateur pi
    su "$TARGET_USER" -c "docker compose down -v --remove-orphans" 2>/dev/null || true
    cd ~ || true
    sudo rm -rf "$PROJECT_DIR"
    log "Dossier prÃ©cÃ©dent supprimÃ©: $PROJECT_DIR"
  fi
  # Suppression conteneurs orphelins nommÃ©s supabase-
  docker rm -f "$(docker ps -a -q --filter "name=supabase-" 2>/dev/null)" 2>/dev/null || true
  # Suppression rÃ©seau par dÃ©faut
  docker network rm supabase_default 2>/dev/null || true
  docker network prune -f 2>/dev/null || true
  # LibÃ©ration ports occupÃ©s (kill processes si nÃ©cessaire)
  local ports=(3000 8001 5432 9999 3001 4000 5000 8082 54321)
  for port in "${ports[@]}"; do
    if command -v lsof &> /dev/null && sudo lsof -i :"$port" &> /dev/null; then
      log "LibÃ©ration port $port (processus en cours)..."
      sudo kill -9 "$(sudo lsof -t -i :"$port")" 2>/dev/null || true
    fi
  done
  ok "Nettoyage terminÃ© - Ports et ressources libÃ©rÃ©s."
}

# CrÃ©ation du dossier projet et volumes avec vÃ©rifications explicites
setup_project_dir() {
  log "ðŸ“ CrÃ©ation du dossier projet et volumes..."
  # CrÃ©ation parent (stacks)
  mkdir -p "$(dirname "$PROJECT_DIR")"
  # CrÃ©ation explicite chaque sous-rÃ©pertoire pour Ã©viter problÃ¨mes expansion braces sous sudo
  mkdir -p "$PROJECT_DIR/volumes/db"
  mkdir -p "$PROJECT_DIR/volumes/auth"
  mkdir -p "$PROJECT_DIR/volumes/realtime"
  mkdir -p "$PROJECT_DIR/volumes/storage"
  mkdir -p "$PROJECT_DIR/volumes/functions/main"
  mkdir -p "$PROJECT_DIR/volumes/kong/logs"
  # Changement propriÃ©taire pour utilisateur pi (Ã©vite sudo pour docker compose)
  sudo chown -R "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR"
  # Permissions larges sur volumes pour compatibilitÃ© Docker
  sudo chmod -R 777 "$PROJECT_DIR/volumes"
  # CrÃ©ation fichier exemple Edge Function (vÃ©rification dir existe avant Ã©criture)
  local function_file="$PROJECT_DIR/volumes/functions/main/index.ts"
  if [[ ! -d "$(dirname "$function_file")" ]]; then
    error "RÃ©pertoire functions/main non crÃ©Ã©: $(dirname "$function_file")"
  fi
  echo 'export default async function handler(req) { return new Response("Hello from Edge!"); }' > "$function_file"
  # VÃ©rification Ã©criture rÃ©ussie
  if [[ ! -f "$function_file" ]]; then
    error "Ã‰chec crÃ©ation fichier index.ts: $function_file"
  fi
  cd "$PROJECT_DIR" || error "Impossible d'accÃ©der au dossier projet: $PROJECT_DIR"
  ok "Dossier projet prÃªt: $(pwd) | Volumes crÃ©Ã©s et chown effectuÃ©s."
}

# GÃ©nÃ©ration ou rÃ©utilisation des secrets (JWT, passwords, keys) avec focus DB_ENC_KEY et APP_NAME
generate_secrets() {
  log "ðŸ” GÃ©nÃ©ration ou rÃ©utilisation des secrets Supabase..."
  local backup_date=$(date +%Y%m%d)
  local backup_file="/home/$TARGET_USER/supabase-secrets-backup-${backup_date}.env"
  if [[ -f "$backup_file" && "$FORCE_RECREATE" != "1" ]]; then
    log "RÃ©utilisation .env de backup rÃ©cent: $backup_file"
    cp "$backup_file" "$PROJECT_DIR/.env"
    # Source pour charger variables
    source "$PROJECT_DIR/.env"
    # ComplÃ©ments si manquants (sÃ©curitÃ©, prioritaire DB_ENC_KEY pour realtime)
    if [[ -z "${DB_ENC_KEY:-}" ]]; then
      log "GÃ©nÃ©ration complÃ©mentaire DB_ENC_KEY (requis pour realtime)..."
      DB_ENC_KEY=$(openssl rand -hex 8)
      export DB_ENC_KEY
      # Mise Ã  jour .env pour Ã©viter WARN
      sed -i "/^DB_ENC_KEY=/d" "$PROJECT_DIR/.env"  # Supprime si vide
      echo "DB_ENC_KEY=$DB_ENC_KEY" >> "$PROJECT_DIR/.env"
    fi
    if [[ -z "${REALTIME_SECRET_KEY_BASE:-}" ]]; then
      log "GÃ©nÃ©ration complÃ©mentaire REALTIME_SECRET_KEY_BASE..."
      REALTIME_SECRET_KEY_BASE="$DB_ENC_KEY"
      export REALTIME_SECRET_KEY_BASE
      sed -i "/^REALTIME_SECRET_KEY_BASE=/d" "$PROJECT_DIR/.env"
      echo "REALTIME_SECRET_KEY_BASE=$REALTIME_SECRET_KEY_BASE" >> "$PROJECT_DIR/.env"
    fi
    # VÃ©rification variables critiques
    local critical_vars=(POSTGRES_PASSWORD JWT_SECRET ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL DB_ENC_KEY)
    for var in "${critical_vars[@]}"; do
      if [[ -z "${!var:-}" ]]; then
        error "Variable critique manquante dans backup: $var"
      fi
    done
    ok "Secrets chargÃ©s depuis backup (JWT prefix: ${JWT_SECRET:0:8}... | DB_ENC_KEY: ${DB_ENC_KEY:0:8}...)"
  else
    log "GÃ©nÃ©ration de nouveaux secrets sÃ©curisÃ©s..."
    POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d '=+/' | cut -c1-32)
    JWT_SECRET=$(openssl rand -hex 32)
    DB_ENC_KEY=$(openssl rand -hex 8)
    local site_url="http://$(hostname -I | awk '{print $1}'):${SUPABASE_PORT}"
    # GÃ©nÃ©ration keys JWT (anon et service_role) basÃ©es sur JWT_SECRET
    ANON_KEY=$(echo -n "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IiIsInJvbGUiOiJhbm9uIiwiaWF0IjoxNDk4MTAwODAwLCJleHAiOjE4MTc0ODQ4MDB9.${JWT_SECRET}" | base64 -w0)
    SERVICE_ROLE_KEY=$(echo -n "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6IiIsInJvbGUiOiJzZXJ2aWNlX3JvbGUiLCJpYXQiOjE0OTgxMDA4MDAsImV4cCI6MTgxNzQ4NDgwMH0.${JWT_SECRET}" | base64 -w0)
    REALTIME_SECRET_KEY_BASE="$DB_ENC_KEY"
    API_EXTERNAL_URL="$site_url"
    SUPABASE_PUBLIC_URL="$site_url"
    # Export pour utilisation (inclut DB_ENC_KEY pour Ã©viter WARN)
    export POSTGRES_PASSWORD JWT_SECRET DB_ENC_KEY REALTIME_SECRET_KEY_BASE ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL APP_NAME
    ok "Nouveaux secrets gÃ©nÃ©rÃ©s - JWT prefix: ${JWT_SECRET:0:8}... | DB_ENC_KEY: ${DB_ENC_KEY:0:8}... | Backup: $backup_file"
  fi
  # Sauvegarde systÃ©matique aprÃ¨s complÃ©ments (avec DB_ENC_KEY et APP_NAME)
  cp "$PROJECT_DIR/.env" "$backup_file"
  echo "APP_NAME=$APP_NAME" >> "$backup_file"  # Ajout pour backup futur
}

# CrÃ©ation du fichier .env optimisÃ© pour ARM64 (16GB RAM, ulimits) avec APP_NAME
create_env_file() {
  log "ðŸ“„ CrÃ©ation du fichier .env optimisÃ© pour Pi5 ARM64..."
  # VÃ©rification toutes variables dÃ©finies (inclut DB_ENC_KEY)
  local vars=(POSTGRES_PASSWORD JWT_SECRET DB_ENC_KEY REALTIME_SECRET_KEY_BASE ANON_KEY SERVICE_ROLE_KEY API_EXTERNAL_URL SUPABASE_PUBLIC_URL)
  for var in "${vars[@]}"; do
    if [[ -z "${!var:-}" ]]; then
      error "Variable manquante pour .env: $var"
    fi
  done
  # GÃ©nÃ©ration dashboard password
  local dashboard_pass=$(openssl rand -base64 16 | tr -d '=+/')
  cat > "$PROJECT_DIR/.env" << ENV
# Supabase .env - OptimisÃ© pour Raspberry Pi 5 ARM64 (16GB RAM, Bookworm)
# Secrets gÃ©nÃ©rÃ©s le $(date)
POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
JWT_SECRET=${JWT_SECRET}
DB_ENC_KEY=${DB_ENC_KEY}  # ClÃ© critique pour realtime (Ã©vite WARN)
REALTIME_SECRET_KEY_BASE=${REALTIME_SECRET_KEY_BASE}
APP_NAME=${APP_NAME}  # Fix boot realtime (RuntimeError: APP_NAME not available)
ANON_KEY=${ANON_KEY}
SERVICE_ROLE_KEY=${SERVICE_ROLE_KEY}
DASHBOARD_USERNAME=supabase
DASHBOARD_PASSWORD=${dashboard_pass}
API_EXTERNAL_URL=${API_EXTERNAL_URL}
SUPABASE_PUBLIC_URL=${SUPABASE_PUBLIC_URL}
POSTGRES_HOST=postgresql
POSTGRES_DB=postgres
POSTGRES_PORT=5432
KONG_HTTP_PORT=${SUPABASE_PORT}
PGRST_DB_SCHEMAS=public,graphql_public,storage,supabase_functions
PGRST_DB_ANON_ROLE=anon
PGRST_JWT_SECRET=${JWT_SECRET}
POSTGRES_SHARED_PRELOAD_LIBRARIES=timescaledb,pg_stat_statements,pgcrypto
POSTGRES_SHARED_BUFFERS=1GB
POSTGRES_WORK_MEM=64MB
POSTGRES_MAINTENANCE_WORK_MEM=256MB
POSTGRES_MAX_CONNECTIONS=200
REALTIME_DB_ENC_KEY=${DB_ENC_KEY}
REALTIME_JWT_SECRET=${JWT_SECRET}
REALTIME_ULIMIT_NOFILE=131072  # AugmentÃ© pour ARM64 (fix Erlang crash)
RLIMIT_NOFILE=131072
GOTRUE_JWT_SECRET=${JWT_SECRET}
GOTRUE_SITE_URL=${SUPABASE_PUBLIC_URL}
GOTRUE_API_EXTERNAL_URL=${API_EXTERNAL_URL}
GOTRUE_DB_DRIVER=postgres
GOTRUE_DISABLE_SIGNUP=false
STORAGE_BACKEND=file
FILE_STORAGE_BACKEND_PATH=/var/lib/storage
IMGPROXY_URL=http://imgproxy:5001
EDGE_RUNTIME_JWT_SECRET=${JWT_SECRET}
SEED_SELF_HOST=true  # Pour migrations realtime self-hosted
ENV
  # Permissions pour utilisateur pi
  chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/.env"
  # VÃ©rification crÃ©ation et DB_ENC_KEY/APP_NAME prÃ©sents
  if [[ ! -f "$PROJECT_DIR/.env" ]]; then
    error "Ã‰chec crÃ©ation .env"
  fi
  if ! grep -q "^DB_ENC_KEY=" "$PROJECT_DIR/.env" || ! grep -q "^APP_NAME=" "$PROJECT_DIR/.env"; then
    error "DB_ENC_KEY ou APP_NAME manquant dans .env aprÃ¨s crÃ©ation"
  fi
  ok ".env crÃ©Ã© et sÃ©curisÃ© - APP_NAME inclus (buffers 1GB, ulimits 131072 pour realtime)."
}

# CrÃ©ation du fichier docker-compose.yml avec APP_NAME et SEED_SELF_HOST pour realtime
create_docker_compose() {
  log "ðŸ³ CrÃ©ation et validation docker-compose.yml..."
  # Contenu YAML avec ressources limitÃ©es pour Pi5 (memory limits, ulimits Realtime 131072) + APP_NAME
  cat > "$PROJECT_DIR/docker-compose.yml" << 'COMPOSE'
services:
  postgresql:
    image: supabase/postgres:15.1.0.147
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - ./volumes/db:/var/lib/postgresql/data
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    deploy:
      resources:
        limits:
          memory: 2G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
  kong:
    image: kong:3.4.0
    ports:
      - "${KONG_HTTP_PORT:-8001}:8000"
    environment:
      KONG_DATABASE: off
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_PREFIX: /var/run/kong_prefix
      KONG_ADMIN_LISTEN: 0.0.0.0:8001
    volumes:
      - ./volumes/kong:/var/run/kong_prefix
    depends_on:
      postgresql:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/status"]
      interval: 5s
      timeout: 5s
      retries: 5
  auth:
    image: supabase/gotrue:v2.153.0
    depends_on:
      postgresql:
        condition: service_started
    environment:
      GOTRUE_JWT_SECRET: ${JWT_SECRET}
      GOTRUE_SITE_URL: ${SUPABASE_PUBLIC_URL}
      GOTRUE_API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      GOTRUE_DB_DRIVER: postgres
    ports:
      - "9999:9999"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9999/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  rest:
    image: postgrest/postgrest:v12.0.2
    depends_on:
      postgresql:
        condition: service_started
    environment:
      PGRST_DB_URI: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_SCHEMAS: public,storage
    ports:
      - "3001:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 5s
      retries: 5
  realtime:
    image: supabase/realtime:v2.34.47
    depends_on:
      postgresql:
        condition: service_started
    environment:
      APP_NAME: ${APP_NAME}  # Fix boot Elixir (RuntimeError: APP_NAME not available)
      SEED_SELF_HOST: true  # Pour migrations self-hosted
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_NAME: postgres
      JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: ${REALTIME_SECRET_KEY_BASE}
      DB_ENC_KEY: ${DB_ENC_KEY}
      PORT: 4000
      HOSTNAME: 0.0.0.0
      ERL_AFLAGS: "-proto_dist inet_tcp"
      RLIMIT_NOFILE: 131072
    ulimits:
      nofile:
        soft: 131072
        hard: 131072
    ports:
      - "4000:4000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  storage:
    image: supabase/storage-api:v1.0.8
    depends_on:
      auth:
        condition: service_started
      rest:
        condition: service_started
      realtime:
        condition: service_started
    environment:
      ANON_KEY: ${ANON_KEY}
      SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@postgresql:5432/postgres
      FILE_STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      STORAGE_BACKEND: file
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
    ports:
      - "5000:5000"
    volumes:
      - ./volumes/storage:/var/lib/storage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  studio:
    image: supabase/studio:latest
    depends_on:
      auth:
        condition: service_started
      rest:
        condition: service_started
      kong:
        condition: service_started
    ports:
      - "3000:3000"
    environment:
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 5s
      timeout: 5s
      retries: 5
  meta:
    image: supabase/postgres-meta:v0.82.0
    depends_on:
      postgresql:
        condition: service_started
    environment:
      PG_META_DB_HOST: postgresql
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "8082:8080"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h postgresql -U postgres && curl -f http://localhost:8080/health"]
      interval: 5s
      timeout: 5s
      retries: 5
  edge-functions:
    image: supabase/edge-runtime:v1.57.1
    depends_on:
      auth:
        condition: service_started
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      VERIFY_JWT: ${JWT_SECRET}
    volumes:
      - ./volumes/functions:/home/deno/functions
    ports:
      - "54321:9000"
    command: ["start", "--main-service", "/home/deno/functions/main"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 5s
      timeout: 5s
      retries: 5
COMPOSE
  # Permissions
  chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/docker-compose.yml"
  # Validation syntaxe YAML
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose config" &> /dev/null; then
    error "Erreur de validation docker-compose.yml - VÃ©rifiez le contenu."
  fi
  ok "docker-compose.yml crÃ©Ã© et validÃ© - APP_NAME=realtime + SEED_SELF_HOST=true pour realtime."
}

# Fonction utilitaire : RÃ©cupÃ¨re liste services unhealthy via parsing Status
get_unhealthy_services() {
  local project_dir="$1"
  su "$TARGET_USER" -c "cd '$project_dir' && docker compose ps --format '{{.Name}} {{.Status}}'" | \
    awk '{ if ($2 ~ /unhealthy/) { print $1 } }' | \
    tr '\n' ' ' | \
    sed 's/ $//' || true
}

# Fonction utilitaire : RÃ©cupÃ¨re liste services exited (fix relance)
get_exited_services() {
  local project_dir="$1"
  su "$TARGET_USER" -c "cd '$project_dir' && docker compose ps --filter 'status=exited' --format '{{.Name}}'" | \
    tr '\n' ' ' | \
    sed 's/ $//' || true
}

# PrÃ©-tÃ©lÃ©chargement des images Docker pour accÃ©lÃ©rer le dÃ©marrage
pre_pull_images() {
  log "ðŸ” PrÃ©-tÃ©lÃ©chargement des images critiques (Ã©vite timeouts Pi5)..."
  local images=(
    "supabase/postgres:15.1.0.147"
    "kong:3.4.0"
    "supabase/gotrue:v2.153.0"
    "postgrest/postgrest:v12.0.2"
    "supabase/realtime:v2.34.47"
    "supabase/storage-api:v1.0.8"
    "supabase/studio:latest"
    "supabase/postgres-meta:v0.82.0"
    "supabase/edge-runtime:v1.57.1"
  )
  for image in "${images[@]}"; do
    log "TÃ©lÃ©chargement de $image..."
    if ! docker pull "$image" &> /dev/null; then
      error "Ã‰chec tÃ©lÃ©chargement image: $image - VÃ©rifiez connexion internet."
    fi
    ok "Image $image tÃ©lÃ©chargÃ©e."
  done
  ok "Toutes les images prÃ©-tÃ©lÃ©chargÃ©es avec succÃ¨s."
}

# Initialisation des migrations PostgreSQL pour Auth (schema + extensions) + sleep pour realtime
init_auth_migrations() {
  log "ðŸ”§ Initialisation des migrations Auth dans PostgreSQL..."
  # DÃ©marrage isolÃ© PostgreSQL
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d postgresql"
  sleep 10  # Attente init DB
  # CrÃ©ation schema auth
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c 'CREATE SCHEMA IF NOT EXISTS auth;'" &> /dev/null; then
    error "Ã‰chec crÃ©ation schema auth."
  fi
  # Activation extension UUID (requis pour migrations)
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql psql -U postgres -d postgres -c 'CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";'" &> /dev/null; then
    error "Ã‰chec activation extension uuid-ossp."
  fi
  sleep 30  # Attente supplÃ©mentaire pour realtime (dÃ©pend PG + DB_ENC_KEY)
  ok "Migrations Auth initialisÃ©es - Schema 'auth' et extension 'uuid-ossp' prÃªts. Sleep 30s pour realtime."
}

# DÃ©ploiement principal : Pull, init, up avec retries healthchecks (focus realtime)
deploy_supabase() {
  log "ðŸš€ DÃ©ploiement complet de Supabase..."
  pre_pull_images
  init_auth_migrations
  # Lancement tous services en detached, pull always pour fraÃ®cheur
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d --pull always"; then
    error "Ã‰chec lancement docker compose up - VÃ©rifiez logs: docker compose logs."
  fi
  sleep 60  # Sleep supplÃ©mentaire pour boot Elixir realtime (post-APP_NAME)
  log "â³ Attente healthchecks et stabilisation (jusqu'Ã  240s, retries automatiques via parsing Status)..."
  local max_wait=48  # 48 * 5s = 240s
  for i in $(seq 1 "$max_wait"); do
    sleep 5
    local status_output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose ps --format 'table {{.Name}}\t{{.Status}}'")
    log "Status itÃ©ration $i/$max_wait:\n$status_output"
    if echo "$status_output" | grep -q "(healthy)\|Up"; then
      local unhealthy=$(get_unhealthy_services "$PROJECT_DIR")
      if [[ -z "$unhealthy" ]]; then
        break  # Tous healthy ou Up
      fi
      warn "Services unhealthy dÃ©tectÃ©s ($i/$max_wait): $unhealthy - Relance automatique (focus realtime/storage)..."
      # Relance ciblÃ©e realtime/storage si prÃ©sents
      [[ "$unhealthy" =~ "realtime" ]] && su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart realtime"
      [[ "$unhealthy" =~ "storage" ]] && su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart storage"
      su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $unhealthy"
    fi
    if [[ $i -eq $max_wait ]]; then
      warn "Timeout healthchecks (240s) - Relance finale realtime/storage pour tolÃ©rance ARM64..."
      su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart realtime storage || true"
    fi
  done
  ok "Services dÃ©ployÃ©s - VÃ©rifiez: cd $PROJECT_DIR && docker compose ps"
}

# Validation finale du dÃ©ploiement (curl hÃ´te pour Ã©viter absence curl dans images) + fix relance exited
validate_deployment() {
  log "ðŸ§ª Validation finale des services Supabase..."
  sleep 120  # Attente supplÃ©mentaire pour sync DB
  local ip=$(hostname -I | awk '{print $1}')
  # Test Studio (3000) - curl hÃ´te
  for i in {1..5}; do
    if curl -s "http://localhost:3000" > /dev/null; then
      ok "Studio accessible (port 3000) - http://$ip:3000"
      break
    fi
    warn "Studio en attente ($i/5)..."
    sleep 5
  done
  [[ $i -le 5 ]] || error "Studio non accessible - VÃ©rifiez logs: docker compose logs studio"
  # Test API (SUPABASE_PORT) - curl hÃ´te
  for i in {1..5}; do
    if curl -s "http://localhost:$SUPABASE_PORT" > /dev/null; then
      ok "API accessible (port $SUPABASE_PORT) - http://$ip:$SUPABASE_PORT"
      break
    fi
    warn "API en attente ($i/5)..."
    sleep 5
  done
  [[ $i -le 5 ]] || error "API non accessible - VÃ©rifiez logs: docker compose logs kong"
  # Test PostgreSQL
  if ! su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T postgresql pg_isready -U postgres" > /dev/null; then
    error "PostgreSQL non prÃªt - VÃ©rifiez logs: docker compose logs postgresql"
  fi
  ok "PostgreSQL connectÃ©."
  # VÃ©rif unhealthy via parsing
  local unhealthy=$(get_unhealthy_services "$PROJECT_DIR")
  if [[ -n "$unhealthy" ]]; then
    warn "Services unhealthy dÃ©tectÃ©s: $unhealthy - Tentative relance finale..."
    su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $unhealthy"
    sleep 30
    local unhealthy_after=$(get_unhealthy_services "$PROJECT_DIR")
    if [[ -n "$unhealthy_after" ]]; then
      # Tests curl hÃ´te pour realtime/storage (tolÃ©rance si KO)
      if ! curl -s "http://localhost:4000/health" > /dev/null; then
        warn "Realtime health KO - Relance manuelle recommandÃ©e: docker compose restart realtime"
      else
        ok "Realtime health OK malgrÃ© status."
      fi
      if ! curl -s "http://localhost:5000/health" > /dev/null; then
        warn "Storage health KO - Relance manuelle recommandÃ©e: docker compose restart storage"
      else
        ok "Storage health OK malgrÃ© status."
      fi
      warn "Supabase partiellement opÃ©rationnel (Studio/API OK) - Surveillez logs pour $unhealthy_after."
    else
      ok "Relance rÃ©ussie - Tous healthy maintenant."
    fi
  fi
  # VÃ©rif exited avec fix relance (vÃ©rif existence avant restart)
  local exited=$(get_exited_services "$PROJECT_DIR")
  if [[ -n "$exited" ]]; then
    warn "Services exited: $exited - Relance auto (vÃ©rif existence)..."
    for svc in $exited; do
      if su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker ps --filter 'name=$svc' --format '{{.Names}}'" | grep -q .; then
        su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart $svc"
        log "RelancÃ©: $svc"
      else
        warn "Service $svc inexistant - Skip relance."
      fi
    done
    sleep 10
  fi
  # Test realtime post-relance
  if curl -s "http://localhost:4000/health" > /dev/null 2>&1; then
    ok "Realtime accessible (port 4000)"
  else
    warn "Realtime non accessible - VÃ©rifiez logs: docker compose logs realtime"
  fi
  # Affichage keys API (sauvegardez-les manuellement!)
  log "ðŸ”‘ Vos API Keys Supabase (sauvegardez-les immÃ©diatement!):"
  grep -E "ANON_KEY|SERVICE_ROLE_KEY" "$PROJECT_DIR/.env" | sed 's/^/   /'
  log "Dashboard: http://$ip:3000 | User: supabase | Pass: (dans .env)"
  ok "Validation complÃ¨te OK! Supabase est opÃ©rationnel."
}

# Flux principal d'exÃ©cution
main() {
  require_root
  check_prereqs
  activate_ufw
  cleanup_previous
  setup_project_dir
  generate_secrets
  create_env_file
  create_docker_compose
  deploy_supabase
  validate_deployment
  log "ðŸŽ‰ DÃ©ploiement Supabase terminÃ© avec succÃ¨s!"
  log "ðŸ“‹ Logs complets: $LOG_FILE"
  log "ðŸš€ Actions manuelles post-install:"
  log "   1. AccÃ©dez Ã  http://$(hostname -I | awk '{print $1}'):3000"
  log "   2. CrÃ©ez un nouveau projet dans Studio."
  log "   3. Notez ANON_KEY et SERVICE_ROLE_KEY depuis .env pour votre app."
  log "   4. Pour arrÃªtez/redÃ©marrer: cd $PROJECT_DIR && docker compose down/up -d"
  log "   5. Si realtime KO persistant: docker compose logs realtime | grep RuntimeError"
  log "   6. Si besoin recreate: sudo FORCE_RECREATE=1 $0"
}

# Lancement main si script direct
main "$@"