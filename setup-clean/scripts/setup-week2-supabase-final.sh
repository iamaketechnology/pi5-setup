#!/usr/bin/env bash
set -euo pipefail

# Gestion des interruptions pour continuer l'installation
trap 'warn "‚ö†Ô∏è Script interrompu mais conteneurs actifs. V√©rifiez: docker compose ps"; exit 130' SIGINT SIGTERM

# === SETUP WEEK2 SUPABASE FINAL - Installation compl√®te avec correctifs Auth/Realtime ===
# Int√®gre les solutions d√©velopp√©es lors des sessions de debugging du 15/09/2025 :
# - Correction erreur PostgreSQL "uuid = text" pour Auth migrations
# - Correction variables encryption Realtime (DB_ENC_KEY, SECRET_KEY_BASE)
# - Pr√©vention corruption YAML docker-compose.yml (indentation)
# - Validation automatique des corrections appliqu√©es

log()  { echo -e "\033[1;36m[SUPABASE]\033[0m $*"; }
warn() { echo -e "\033[1;33m[WARN]    \033[0m $*"; }
ok()   { echo -e "\033[1;32m[OK]      \033[0m $*"; }
error() { echo -e "\033[1;31m[ERROR]  \033[0m $*"; }

# Variables globales
SCRIPT_VERSION="2.4-env-protection-critical-validation"
LOG_FILE="/var/log/pi5-setup-week2-supabase-${SCRIPT_VERSION}-$(date +%Y%m%d_%H%M%S).log"
TARGET_USER="${SUDO_USER:-pi}"
PROJECT_DIR="/home/$TARGET_USER/stacks/supabase"

# Configuration par d√©faut
SUPABASE_PORT="${SUPABASE_PORT:-8001}"  # Port par d√©faut pour √©viter conflits
FORCE="${FORCE:-0}"  # Protection donn√©es: FORCE=1 pour √©craser

require_root() {
  if [[ "$EUID" -ne 0 ]]; then
    echo "Usage: sudo $0"
    exit 1
  fi
}

check_dependencies() {
  log "üîç V√©rification des d√©pendances..."
  local dependencies=("curl" "git" "openssl" "docker" "gpg" "netstat" "jq")
  local missing_deps=()

  for dep in "${dependencies[@]}"; do
    if ! command -v "$dep" &> /dev/null; then
      missing_deps+=("$dep")
    fi
  done

  if [ ${#missing_deps[@]} -gt 0 ]; then
    warn "‚ö†Ô∏è D√©pendances manquantes : ${missing_deps[*]}"
    log "   Installation automatique des d√©pendances manquantes..."

    apt update >/dev/null 2>&1
    for dep in "${missing_deps[@]}"; do
      case "$dep" in
        "jq") apt install -y jq >/dev/null 2>&1 ;;
        "netstat") apt install -y net-tools >/dev/null 2>&1 ;;
        "gpg") apt install -y gpg >/dev/null 2>&1 ;;
        *) apt install -y "$dep" >/dev/null 2>&1 ;;
      esac
      log "     Install√©: $dep"
    done
    ok "‚úÖ D√©pendances install√©es automatiquement"
  fi
  ok "‚úÖ Toutes les d√©pendances sont pr√©sentes."
}

# =============================================================================
# CONFIGURATION VERSIONS DOCKER - Centralisation pour maintenance facile
# Source: https://github.com/supabase/supabase/blob/master/docker/docker-compose.yml
# =============================================================================

# Versions principales Supabase (mise √† jour 2025)
readonly POSTGRES_VERSION="15-alpine"
readonly GOTRUE_VERSION="v2.177.0"
readonly POSTGREST_VERSION="v12.2.0"
readonly REALTIME_VERSION="v2.30.23"
readonly STORAGE_API_VERSION="v1.11.6"
readonly POSTGRES_META_VERSION="v0.83.2"
readonly STUDIO_VERSION="20250106-e00ba41"
readonly EDGE_RUNTIME_VERSION="v1.58.2"

# Versions services compl√©mentaires ARM64 optimis√©es
readonly KONG_VERSION="3.0.0"                    # ARM64v8 sp√©cifique
readonly IMGPROXY_VERSION="v3.8.0"               # Compatible ARM64

# Configuration PostgreSQL optimis√©e Pi 5 (16GB RAM)
readonly POSTGRES_DB="postgres"
readonly POSTGRES_SHARED_BUFFERS="1GB"
readonly POSTGRES_WORK_MEM="64MB"
readonly POSTGRES_MAINTENANCE_WORK_MEM="256MB"
readonly POSTGRES_MAX_CONNECTIONS="200"

# =============================================================================

setup_logging() {
  exec 1> >(tee -a "$LOG_FILE")
  exec 2> >(tee -a "$LOG_FILE" >&2)

  log "=== Pi 5 Supabase Installation Final - $(date) ==="
  log "Version: $SCRIPT_VERSION"
  log "Utilisateur cible: $TARGET_USER"
  log "R√©pertoire projet: $PROJECT_DIR"
}

check_prerequisites() {
  log "üîç V√©rification pr√©requis syst√®me avec logs d√©taill√©s..."

  # Log informations syst√®me de base pour debug
  log "   Syst√®me: $(uname -a | cut -d' ' -f1-3)"
  log "   Architecture: $(uname -m)"
  log "   RAM totale: $(free -h | grep Mem | awk '{print $2}')"
  log "   Espace disque: $(df -h / | tail -1 | awk '{print $4}') disponible"

  # V√©rifier Week1 install√©
  if ! command -v docker >/dev/null; then
    error "‚ùå Docker non install√© - Lancer d'abord Week1 Enhanced"
    log ""
    log "   üìã Commandes pour installer Docker :"
    log "   curl -fsSL https://raw.githubusercontent.com/iamaketechnology/pi5-setup/main/setup-clean/scripts/setup-week1-enhanced-final.sh | sudo bash"
    log "   # OU manuellement :"
    log "   curl -fsSL https://get.docker.com | bash"
    log "   sudo usermod -aG docker pi && sudo systemctl enable docker"
    exit 1
  fi

  if ! docker compose version >/dev/null 2>&1; then
    error "‚ùå Docker Compose v2 non install√©"
    log ""
    log "   üìã Commandes pour installer Docker Compose :"
    log "   sudo apt update && sudo apt install -y docker-compose-plugin"
    log "   # V√©rifier : docker compose version"
    exit 1
  fi

  # Log version Docker pour debug
  local docker_version=$(docker --version | cut -d' ' -f3 | cut -d',' -f1)
  log "   Docker: $docker_version"

  # **CRITIQUE: V√©rifier page size (probl√®me principal Pi 5)**
  local page_size=$(getconf PAGESIZE 2>/dev/null || echo "0")
  if [[ "$page_size" == "4096" ]]; then
    ok "‚úÖ Page size: ${page_size}B - Images officielles"
  elif [[ "$page_size" == "16384" ]]; then
    error "‚ùå Page size 16KB - INCOMPATIBLE avec PostgreSQL"
    echo ""
    echo "üîß **SOLUTION REQUISE** :"
    echo "   1. Ajouter 'kernel=kernel8.img' √† /boot/firmware/config.txt"
    echo "   2. Red√©marrer le Pi : sudo reboot"
    echo "   3. V√©rifier : getconf PAGESIZE doit retourner 4096"
    echo ""
    exit 1
  else
    warn "‚ö†Ô∏è Page size non standard: ${page_size}B"
  fi

  # V√©rifier entropie syst√®me (kernels modernes 5.17+ avec BLAKE2s)
  local entropy=$(cat /proc/sys/kernel/random/entropy_avail 2>/dev/null || echo "0")
  if [[ $entropy -eq 256 ]]; then
    ok "‚úÖ Entropie syst√®me: $entropy bits (CSPRNG kernel moderne initialis√©)"
  elif [[ $entropy -gt 256 ]]; then
    ok "‚úÖ Entropie syst√®me: $entropy bits (ancien kernel ou pool en remplissage)"
  elif [[ $entropy -lt 200 ]]; then
    warn "‚ö†Ô∏è Entropie syst√®me: $entropy bits (CSPRNG possiblement non initialis√©)"
    log "   Hardware RNG Pi 5 doit semer le pool d'entropie"
  else
    ok "‚úÖ Entropie syst√®me: $entropy bits"
  fi

  # V√©rifier Docker daemon limits pour ARM64
  if command -v systemctl >/dev/null; then
    local docker_nofile=$(systemctl show docker.service --property=LimitNOFILE 2>/dev/null | cut -d= -f2)
    if [[ "$docker_nofile" == "infinity" ]] || [[ $docker_nofile -ge 65536 ]]; then
      ok "‚úÖ Docker daemon file limits: $docker_nofile"
    else
      warn "‚ö†Ô∏è Docker daemon file limits: $docker_nofile (recommand√©: >=65536)"
      log "   Des services comme Realtime peuvent red√©marrer avec des limites faibles"
    fi
  fi

  ok "Pr√©requis valid√©s"
}

check_port_conflicts() {
  log "üîç V√©rification conflits de ports..."

  local supabase_ports=(3000 $SUPABASE_PORT 5432 54321)
  local conflicted_ports=()

  for port in "${supabase_ports[@]}"; do
    if netstat -tuln 2>/dev/null | grep -q ":$port "; then
      conflicted_ports+=("$port")
    fi
  done

  if [[ ${#conflicted_ports[@]} -gt 0 ]]; then
    echo ""
    echo "üîÑ RELANCEMENT D√âTECT√â - Installation Supabase existante trouv√©e"
    warn "‚ö†Ô∏è Ports occup√©s: ${conflicted_ports[*]}"
    echo ""

    # D√©tecter et arr√™ter installation Supabase existante
    if [[ -d "$PROJECT_DIR" ]] && [[ -f "$PROJECT_DIR/docker-compose.yml" ]]; then
      echo "üí° MODE RELANCEMENT AUTOMATIQUE ACTIV√â"
      echo "   Le script va arr√™ter proprement l'installation existante"
      echo "   puis r√©installer avec les derni√®res corrections"
      echo ""

      log "üõë Installation Supabase existante d√©tect√©e - arr√™t automatique..."

      cd "$PROJECT_DIR" 2>/dev/null && {
        log "   Arr√™t des services Supabase en cours..."
        if timeout 30 su "$TARGET_USER" -c "docker compose down" 2>/dev/null; then
          ok "‚úÖ Services Supabase arr√™t√©s proprement"
        else
          warn "‚ö†Ô∏è Arr√™t timeout - force kill..."
          su "$TARGET_USER" -c "docker compose kill" 2>/dev/null || true
          su "$TARGET_USER" -c "docker compose rm -f" 2>/dev/null || true
          ok "‚úÖ Services Supabase forc√©s √† l'arr√™t"
        fi

        # Attendre que les ports se lib√®rent avec feedback
        echo "   ‚è±Ô∏è  Lib√©ration des ports... 5 secondes"
        sleep 5
        ok "‚úÖ Ports lib√©r√©s - relancement en cours..."
      }
    fi

    # Gestion conflit Portainer port 8000
    if [[ " ${conflicted_ports[*]} " =~ " 8000 " ]]; then
      log "   Migration Portainer 8000 ‚Üí 8080 si n√©cessaire..."

      if docker ps --format "{{.Names}}" | grep -q "^portainer$"; then
        local portainer_port=$(docker port portainer 2>/dev/null | grep "9000/tcp" | cut -d: -f2 || echo "unknown")
        if [[ "$portainer_port" == "8000" ]]; then
          log "   Reconfiguration Portainer vers port 8080..."
          docker stop portainer >/dev/null 2>&1 || true
          docker rm portainer >/dev/null 2>&1 || true
          docker run -d -p 8080:9000 --name portainer --restart=always \
            -v /var/run/docker.sock:/var/run/docker.sock \
            -v portainer_data:/data portainer/portainer-ce:latest >/dev/null 2>&1
          ok "‚úÖ Portainer migr√© vers port 8080"
        fi
      fi
    fi

    # V√©rification finale apr√®s arr√™ts
    conflicted_ports=()
    for port in "${supabase_ports[@]}"; do
      if netstat -tuln 2>/dev/null | grep -q ":$port "; then
        conflicted_ports+=("$port")
      fi
    done

    if [[ ${#conflicted_ports[@]} -gt 0 ]]; then
      error "‚ùå Ports toujours occup√©s apr√®s nettoyage: ${conflicted_ports[*]}"
      echo ""
      echo "üìã Solutions manuelles :"
      echo "   # Identifier les processus utilisant les ports"
      for port in "${conflicted_ports[@]}"; do
        echo "   lsof -i :$port"
      done
      echo ""
      echo "   # OU forcer un reset complet avec le script cleanup"
      echo "   curl -fsSL https://raw.githubusercontent.com/iamaketechnology/pi5-setup/main/setup-clean/scripts/cleanup-week2-supabase.sh -o cleanup.sh"
      echo "   chmod +x cleanup.sh && sudo ./cleanup.sh"
      exit 1
    fi
  fi

  ok "‚úÖ Aucun conflit de port d√©tect√©"
}

ensure_working_directory() {
  log "üìÅ S√©curisation r√©pertoire de travail..."
  cd /

  if [[ -d "$PROJECT_DIR" ]]; then
    # V√©rifier si des donn√©es DB existent
    if [[ -d "$PROJECT_DIR/volumes/db" ]] && [[ -n "$(ls -A "$PROJECT_DIR/volumes/db" 2>/dev/null)" ]] && [[ "$FORCE" != "1" ]]; then
      error "‚ùå $PROJECT_DIR existe et contient des donn√©es DB."
      error "   Abandon pour √©viter perte de donn√©es."
      error "   Lance avec FORCE=1 pour √©craser: FORCE=1 sudo $0"
      exit 1
    fi
    log "   Nettoyage ancien r√©pertoire..."
    rm -rf "$PROJECT_DIR" 2>/dev/null || true
  fi

  # Cr√©er r√©pertoire parent avec permissions appropri√©es
  local parent_dir="$(dirname "$PROJECT_DIR")"
  mkdir -p "$parent_dir"

  # Si le parent est /home/pi/stacks, s'assurer qu'il appartient √† l'utilisateur
  if [[ "$parent_dir" =~ ^/home/[^/]+/stacks$ ]]; then
    chown "$TARGET_USER:$TARGET_USER" "$parent_dir"
    log "   Permissions parent corrig√©es: $parent_dir"
  fi

  # Cr√©er le r√©pertoire projet avec les bonnes permissions
  mkdir -p "$PROJECT_DIR"
  chown -R "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR"

  # V√©rifier cr√©ation effective
  if [[ ! -d "$PROJECT_DIR" ]]; then
    error "‚ùå Impossible de cr√©er $PROJECT_DIR"
    exit 1
  fi

  # Se placer dans le r√©pertoire
  cd "$PROJECT_DIR"

  ok "‚úÖ R√©pertoire de travail s√©curis√©: $(pwd) (permissions auto-corrig√©es)"
}

optimize_system_for_supabase() {
  log "üîß Optimisation syst√®me pour Supabase ARM64..."

  # 1. V√©rifier que Week 1 a configur√© l'entropie
  log "üîç V√©rification configuration entropie (doit √™tre fait par Week 1)..."

  if systemctl is-active rng-tools-debian >/dev/null 2>&1 || systemctl is-active rngd >/dev/null 2>&1; then
    ok "‚úÖ Service RNG actif (configur√© par Week 1)"
  else
    warn "‚ö†Ô∏è Aucun service RNG d√©tect√© - Week 1 incomplet ?"
    log "   Red√©marrez Week 1 pour configurer les sources d'entropie"
  fi

  # 2. V√©rifier que le CSPRNG kernel est initialis√©
  if dmesg | grep -q "random: crng init done"; then
    ok "‚úÖ CSPRNG kernel initialis√© - entropie suffisante"
  else
    log "   CSPRNG en cours d'initialisation..."
  fi

  # 3. Configurer Docker daemon pour des limits appropri√©es
  local docker_override_dir="/etc/systemd/system/docker.service.d"
  local docker_override_file="$docker_override_dir/override.conf"

  if [[ ! -f "$docker_override_file" ]]; then
    log "üê≥ Configuration des limites Docker daemon..."
    mkdir -p "$docker_override_dir"

    cat > "$docker_override_file" << 'DOCKER_OVERRIDE'
[Service]
LimitNOFILE=1048576
LimitNPROC=1048576
LimitCORE=infinity
TasksMax=infinity
DOCKER_OVERRIDE

    systemctl daemon-reload
    systemctl restart docker
    ok "‚úÖ Limites Docker daemon configur√©es"
  else
    log "‚ÑπÔ∏è Limites Docker daemon d√©j√† configur√©es"
  fi

  # 4. V√©rification entropie finale (kernel moderne)
  local entropy=$(cat /proc/sys/kernel/random/entropy_avail 2>/dev/null || echo "0")
  if [[ $entropy -eq 256 ]]; then
    ok "‚úÖ Entropie: $entropy bits (CSPRNG kernel moderne - optimal)"
  elif [[ $entropy -gt 256 ]]; then
    ok "‚úÖ Entropie: $entropy bits (bon niveau)"
  else
    ok "‚úÖ Entropie: $entropy bits (continuons l'installation)"
    log "   Kernel moderne : l'entropie 256 est suffisante pour Supabase"
  fi
}

create_project_structure() {
  log "üìÅ Cr√©ation structure projet robuste..."

  # S'assurer que nous sommes dans un r√©pertoire s√ªr
  cd /

  log "   Cr√©ation structure projet: $PROJECT_DIR"

  # Cr√©er structure compl√®te avec functions et config
  su "$TARGET_USER" -c "mkdir -p '$PROJECT_DIR'/{volumes/{db,storage,kong,functions},scripts,backups,config}"

  # CRITIQUE: Permissions Docker pour √©viter getcwd errors
  # Utiliser UID/GID 1000 (utilisateur pi standard) pour tous les volumes
  chown -R 1000:1000 "$PROJECT_DIR"

  # Permissions sp√©ciales pour services avec UIDs sp√©cifiques
  chown -R 999:999 "$PROJECT_DIR/volumes/db" 2>/dev/null || true  # PostgreSQL
  chown -R 100:101 "$PROJECT_DIR/volumes/kong" 2>/dev/null || true  # Kong

  # Permissions ex√©cution sur tous parents (√©viter permission denied)
  chmod -R o+x "$(dirname "$PROJECT_DIR")" 2>/dev/null || true
  chmod -R 755 "$PROJECT_DIR"

  # Cr√©er fonction edge par d√©faut (corrig√©e pour 2025)
  create_default_edge_function

  # Cr√©er template Kong (√©viter permission denied sur kong.yml)
  create_kong_template

  # Se placer dans le r√©pertoire pour √©viter getcwd
  cd "$PROJECT_DIR"

  ok "‚úÖ Structure cr√©√©e et s√©curis√©e: $(pwd)"
}

create_default_edge_function() {
  log "‚ö° Cr√©ation fonction Edge par d√©faut (corrig√©e 2025)..."

  # Cr√©er r√©pertoire hello pour edge functions (--main-service requis)
  mkdir -p "$PROJECT_DIR/volumes/functions/hello"

  # Cr√©er index.ts par d√©faut (format 2025 simplifi√©)
  cat > "$PROJECT_DIR/volumes/functions/hello/index.ts" << 'EDGE_FUNCTION'
// Pi 5 ARM64 Edge Function - 2025 Format
export default async (req: Request) => {
  try {
    const body = await req.json().catch(() => ({}))
    const { name = "Pi 5" } = body

    const data = {
      message: `Hello from ${name}!`,
      timestamp: new Date().toISOString(),
      platform: "Pi 5 ARM64",
      status: "running"
    }

    return new Response(
      JSON.stringify(data),
      {
        status: 200,
        headers: { "Content-Type": "application/json" }
      }
    )
  } catch (error) {
    return new Response(
      JSON.stringify({ error: error.message }),
      {
        status: 500,
        headers: { "Content-Type": "application/json" }
      }
    )
  }
}
EDGE_FUNCTION

  # Permissions UID/GID 1000 pour √©viter conflicts
  chown -R 1000:1000 "$PROJECT_DIR/volumes/functions"
  chmod -R 755 "$PROJECT_DIR/volumes/functions"

  ok "‚úÖ Fonction Edge 'hello' cr√©√©e avec --main-service support"
}

create_kong_template() {
  log "üîß Cr√©ation template Kong (√©viter permission denied)..."

  # Cr√©er template Kong.yml (sera processs√© par envsubst)
  cat > "$PROJECT_DIR/config/kong.tpl.yml" << 'KONG_TEMPLATE'
_format_version: "3.0"
_transform: true

services:
  - name: auth-v1-open
    url: http://auth:9999/verify
    routes:
      - name: auth-v1-open
        strip_path: true
        paths:
          - /auth/v1/verify
        methods:
          - POST
          - GET

  - name: auth-v1-open-callback
    url: http://auth:9999/callback
    routes:
      - name: auth-v1-open-callback
        strip_path: true
        paths:
          - /auth/v1/callback
        methods:
          - POST
          - GET

  - name: auth-v1-open-authorize
    url: http://auth:9999/authorize
    routes:
      - name: auth-v1-open-authorize
        strip_path: true
        paths:
          - /auth/v1/authorize
        methods:
          - POST
          - GET

  - name: auth-v1
    _comment: "GoTrue: /auth/v1/* -> http://auth:9999/*"
    url: http://auth:9999/
    routes:
      - name: auth-v1-all
        strip_path: true
        paths:
          - /auth/v1/
        methods:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE

  - name: rest-v1
    _comment: "PostgREST: /rest/v1/* -> http://rest:3000/*"
    url: http://rest:3000/
    routes:
      - name: rest-v1-all
        strip_path: true
        paths:
          - /rest/v1/
        methods:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE

  - name: realtime-v1-ws
    _comment: "Realtime: Secure WebSockets -> ws://realtime:4000/socket/*"
    url: http://realtime:4000/socket/
    routes:
      - name: realtime-v1-ws
        strip_path: true
        paths:
          - /realtime/v1/
        methods:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE

  - name: storage-v1
    _comment: "Storage: /storage/v1/* -> http://storage:5000/*"
    url: http://storage:5000/
    routes:
      - name: storage-v1-all
        strip_path: true
        paths:
          - /storage/v1/
        methods:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE

  - name: edge-functions-v1
    _comment: "Edge Functions: /functions/v1/* -> http://edge-functions:9000/*"
    url: http://edge-functions:9000/
    routes:
      - name: edge-functions-v1-all
        strip_path: true
        paths:
          - /functions/v1/
        methods:
          - POST
          - GET
          - PUT
          - PATCH
          - DELETE

  - name: meta
    url: http://meta:8080/
    routes:
      - name: meta-all
        strip_path: true
        paths:
          - /
        methods:
          - POST
          - GET
KONG_TEMPLATE

  # Permissions
  chown -R 1000:1000 "$PROJECT_DIR/config"
  chmod 644 "$PROJECT_DIR/config/kong.tpl.yml"

  ok "‚úÖ Template Kong cr√©√©: config/kong.tpl.yml"
}

generate_secure_jwt_secret() {
  log "üîê G√©n√©ration JWT_SECRET s√©curis√© (une seule ligne)..."

  # G√©n√©rer JWT_SECRET sur UNE SEULE ligne garantie (√©vite probl√®me multi-lignes)
  local jwt_secret=$(openssl rand -base64 64 | tr -d '\n' | tr -d '/' | tr -d '+' | tr -d '=')

  # V√©rifier longueur minimale pour cryptographie Realtime
  if [[ ${#jwt_secret} -lt 50 ]]; then
    log "‚ö†Ô∏è JWT_SECRET trop court, r√©g√©n√©ration avec hex..."
    jwt_secret=$(openssl rand -hex 32)  # Fallback hex (64 caract√®res garantis)
  fi

  log "‚úÖ JWT_SECRET g√©n√©r√© : ${#jwt_secret} caract√®res (single-line)"
  export JWT_SECRET="$jwt_secret"
}

# =============================================================================
# CORRECTION REALTIME ENCRYPTION - INT√âGRATION COMPL√àTE
# Bas√© sur session de debugging 15/09/2025 - R√©solution crypto_one_time error
# =============================================================================

prepare_realtime_encryption_keys() {
  log "üîë G√©n√©ration cl√©s Realtime encryption (correction int√©gr√©e)..."

  # DB_ENC_KEY: EXACTEMENT 16 caract√®res ASCII pour AES-128-ECB (8 octets ‚Üí 16 hex)
  # CRITIQUE: Realtime crash avec "crypto_one_time(:aes_128_ecb, nil)" si absent/incorrect
  DB_ENC_KEY=$(openssl rand -hex 8)

  # SECRET_KEY_BASE: 64 caract√®res minimum pour Elixir (32 octets ‚Üí 64 hex)
  # CRITIQUE: "APP_NAME not available" si absent ou trop court
  SECRET_KEY_BASE=$(openssl rand -hex 32)

  # JWT_SECRET optimal: ~40 caract√®res (retour terrain 2024-2025)
  # Si JWT_SECRET existant trop long, le raccourcir pour √©viter instabilit√©
  if [[ ${#JWT_SECRET} -gt 50 ]]; then
    log "   JWT_SECRET trop long (${#JWT_SECRET} chars), raccourci √† 40 pour stabilit√©"
    JWT_SECRET=$(echo "$JWT_SECRET" | head -c 40)
  fi

  # Export pour utilisation globale (critique pour create_env_file)
  export DB_ENC_KEY SECRET_KEY_BASE JWT_SECRET

  ok "‚úÖ Cl√©s Realtime g√©n√©r√©es (format valid√© par debugging):"
  log "   DB_ENC_KEY: ${DB_ENC_KEY} (16 chars - AES-128 compatible)"
  log "   SECRET_KEY_BASE: ${SECRET_KEY_BASE:0:16}... (64 chars - Elixir compatible)"
  log "   JWT_SECRET: ${JWT_SECRET:0:16}... (${#JWT_SECRET} chars - optimal)"
}

generate_secure_secrets() {
  log "üîê G√©n√©ration secrets s√©curis√©s..."

  # G√©n√©rer JWT_SECRET s√©curis√© d'abord (√©vite multi-lignes)
  generate_secure_jwt_secret

  # NOUVEAU: G√©n√©rer cl√©s Realtime encryption sp√©cifiques (CORRECTION INT√âGR√âE)
  prepare_realtime_encryption_keys

  # G√©n√©ration s√©curis√©e (sans caract√®res sp√©ciaux probl√©matiques)
  local postgres_password=$(openssl rand -base64 32 | tr -d "=+/@#\$&*" | cut -c1-25)

  # IMPORTANT: Ces cl√©s sont coh√©rentes avec un JWT_SECRET fixe pour d√©mo
  # En production, r√©g√©n√©rer anon_key et service_key √† partir du JWT_SECRET
  local anon_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJvbGUiOiJhbm9uIiwiaWF0IjoxNjQ1MTkwNzI0LCJleHAiOjE5NjA3NjY3MjR9.M9jrxyvPLkUxWgOYSf5dNdJ8v_eWrqwU7WgMaOFErDg"
  local service_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJvbGUiOiJzZXJ2aWNlX3JvbGUiLCJpYXQiOjE2NDUxOTA3MjQsImV4cCI6MTk2MDc2NjcyNH0.T49KQx5LzLqbNBDOgdYlCW0Rf7cCUfz1bVy9q_Tl2X8"

  log "   ‚ö†Ô∏è Utilisation cl√©s JWT d√©mo - Pour production: r√©g√©n√©rer depuis JWT_SECRET"

  # D√©tecter IP locale
  local local_ip=$(hostname -I | awk '{print $1}')

  # Exporter pour utilisation dans les fonctions
  export POSTGRES_PASSWORD="$postgres_password"
  export SUPABASE_ANON_KEY="$anon_key"
  export SUPABASE_SERVICE_KEY="$service_key"
  export LOCAL_IP="$local_ip"
  export SUPABASE_PUBLIC_URL="http://$local_ip:$SUPABASE_PORT"
  export API_EXTERNAL_URL="http://$local_ip:$SUPABASE_PORT"

  ok "‚úÖ Secrets g√©n√©r√©s pour IP: $local_ip"
  log "   API accessible sur: http://$local_ip:$SUPABASE_PORT"
}

# Protection et validation du fichier .env
validate_env_file() {
  local env_file="$1"

  if [[ ! -f "$env_file" ]]; then
    error "‚ùå Fichier .env manquant : $env_file"
    return 1
  fi

  log "üîç Validation fichier .env..."

  # Variables critiques obligatoires
  local required_vars=(
    "SUPABASE_PORT"
    "POSTGRES_PASSWORD"
    "JWT_SECRET"
    "SUPABASE_ANON_KEY"
    "SUPABASE_SERVICE_KEY"
    "LOCAL_IP"
  )

  local missing_vars=()
  for var in "${required_vars[@]}"; do
    if ! grep -q "^${var}=" "$env_file"; then
      missing_vars+=("$var")
    fi
  done

  if [[ ${#missing_vars[@]} -gt 0 ]]; then
    error "‚ùå Variables manquantes dans .env : ${missing_vars[*]}"
    return 1
  fi

  # V√©rifier que SUPABASE_PORT n'est pas vide
  local supabase_port=$(grep "^SUPABASE_PORT=" "$env_file" | cut -d'=' -f2 | tr -d '"')
  if [[ -z "$supabase_port" ]]; then
    error "‚ùå SUPABASE_PORT est vide dans .env"
    return 1
  fi

  ok "‚úÖ Fichier .env valid√© (${#required_vars[@]} variables critiques pr√©sentes)"
  return 0
}

backup_env_file() {
  local env_file="$1"

  if [[ -f "$env_file" ]]; then
    local backup_file="${env_file}.bak.$(date +%Y%m%d_%H%M%S)"
    cp "$env_file" "$backup_file"
    log "üíæ Sauvegarde .env : $backup_file"

    # Prot√©ger contre suppression accidentelle
    chmod 444 "$backup_file"
  fi
}

restore_env_if_missing() {
  local env_file="$1"

  if [[ ! -f "$env_file" ]]; then
    warn "‚ö†Ô∏è  Fichier .env manquant, tentative de restauration..."

    # Chercher la sauvegarde la plus r√©cente
    local latest_backup
    latest_backup=$(ls -1t "${env_file}".bak.* 2>/dev/null | head -1)

    if [[ -n "$latest_backup" && -f "$latest_backup" ]]; then
      cp "$latest_backup" "$env_file"
      chmod 600 "$env_file"
      chown "$TARGET_USER:$TARGET_USER" "$env_file"
      ok "‚úÖ Fichier .env restaur√© depuis : $latest_backup"
      return 0
    else
      error "‚ùå Aucune sauvegarde .env trouv√©e pour restauration"
      return 1
    fi
  fi

  return 0
}

create_env_file() {
  log "üìÑ Cr√©ation fichier .env avec variables correctes..."

  # Sauvegarder fichier existant si pr√©sent
  backup_env_file "$PROJECT_DIR/.env"

  # Cr√©er un fichier temporaire s√©curis√©
  local tmp_file
  tmp_file=$(mktemp)

  # Cr√©er .env avec TOUTES les variables n√©cessaires dans le fichier temporaire
  cat > "$tmp_file" << EOF
# Pi 5 Supabase Configuration Final
# Generated: $(date)

########################################
# Docker Images Versions (Centralis√©es)
########################################
POSTGRES_VERSION=$POSTGRES_VERSION
GOTRUE_VERSION=$GOTRUE_VERSION
POSTGREST_VERSION=$POSTGREST_VERSION
REALTIME_VERSION=$REALTIME_VERSION
STORAGE_API_VERSION=$STORAGE_API_VERSION
POSTGRES_META_VERSION=$POSTGRES_META_VERSION
STUDIO_VERSION=$STUDIO_VERSION
EDGE_RUNTIME_VERSION=$EDGE_RUNTIME_VERSION
KONG_VERSION=$KONG_VERSION
IMGPROXY_VERSION=$IMGPROXY_VERSION

########################################
# Core Database
########################################
POSTGRES_PASSWORD=$POSTGRES_PASSWORD
POSTGRES_DB=postgres
POSTGRES_USER=postgres

# **CRITIQUE: UN SEUL MOT DE PASSE pour √©viter erreurs auth**
# Tous les services utilisent POSTGRES_PASSWORD

########################################
# JWT & Authentication
########################################
JWT_SECRET=$JWT_SECRET
SUPABASE_ANON_KEY=$SUPABASE_ANON_KEY
SUPABASE_SERVICE_KEY=$SUPABASE_SERVICE_KEY

########################################
# Network Configuration
########################################
LOCAL_IP=$LOCAL_IP
SUPABASE_PORT=$SUPABASE_PORT

########################################
# API & URLs
########################################
SUPABASE_PUBLIC_URL=http://$LOCAL_IP:$SUPABASE_PORT
API_EXTERNAL_URL=http://$LOCAL_IP:$SUPABASE_PORT

########################################
# Pi 5 PostgreSQL Optimizations (16GB RAM)
########################################
POSTGRES_SHARED_BUFFERS=1GB
POSTGRES_WORK_MEM=64MB
POSTGRES_MAINTENANCE_WORK_MEM=256MB
POSTGRES_MAX_CONNECTIONS=200
POSTGRES_EFFECTIVE_CACHE_SIZE=8GB

########################################
# Docker Configuration
########################################
DOCKER_SOCKET_LOCATION=/var/run/docker.sock

########################################
# Ports (√©viter conflits)
########################################
KONG_HTTP_PORT=$SUPABASE_PORT

########################################
# Development
########################################
ENVIRONMENT=development

########################################
# Realtime Encryption (CORRECTION INT√âGR√âE)
# Variables critiques pour √©viter crypto_one_time error
########################################
DB_ENC_KEY=$DB_ENC_KEY
SECRET_KEY_BASE=$SECRET_KEY_BASE

EOF

  # Si l'√©criture a r√©ussi, d√©placer le fichier temporaire √† sa destination finale
  if [ $? -eq 0 ]; then
    mv "$tmp_file" "$PROJECT_DIR/.env"
    chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/.env"
    chmod 600 "$PROJECT_DIR/.env"  # Permissions s√©curis√©es pour les secrets

    # VALIDATION CRITIQUE : V√©rifier que le fichier .env est complet
    if validate_env_file "$PROJECT_DIR/.env"; then
      ok "‚úÖ Fichier .env cr√©√© et valid√© avec √©criture atomique"
    else
      error "‚ùå Validation .env √©chou√©e apr√®s cr√©ation"
      return 1
    fi
  else
    error "‚ùå √âchec de la cr√©ation du fichier .env temporaire."
    rm -f "$tmp_file"
    return 1
  fi
}

create_docker_compose() {
  log "üê≥ Cr√©ation docker-compose.yml optimis√© avec variables..."

  # Docker-compose unifi√© avec corrections compl√®tes
  cat > "$PROJECT_DIR/docker-compose.yml" << 'COMPOSE'
services:
  # Base de donn√©es PostgreSQL optimis√©e Pi 5
  db:
    container_name: supabase-db
    image: postgres:${POSTGRES_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    command:
      - "postgres"
      - "-c"
      - "shared_buffers=${POSTGRES_SHARED_BUFFERS}"
      - "-c"
      - "work_mem=${POSTGRES_WORK_MEM}"
      - "-c"
      - "maintenance_work_mem=${POSTGRES_MAINTENANCE_WORK_MEM}"
      - "-c"
      - "max_connections=${POSTGRES_MAX_CONNECTIONS}"
      - "-c"
      - "wal_level=logical"
      - "-c"
      - "max_wal_senders=10"
      - "-c"
      - "max_replication_slots=10"
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: postgres
      # PostgreSQL Alpine init
      POSTGRES_INITDB_ARGS: "--data-checksums --auth-host=md5"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
      interval: 45s
      timeout: 20s
      retries: 8
      start_period: 90s
    deploy:
      resources:
        limits:
          memory: 1GB  # Optimis√© Pi 5 : 2GB‚Üí1GB
          cpus: '1.5'
    volumes:
      - ./volumes/db:/var/lib/postgresql/data:Z
    ports:
      - "127.0.0.1:5432:5432"

  # Service Auth (GoTrue) - MOT DE PASSE UNIFI√â
  auth:
    container_name: supabase-auth
    image: supabase/gotrue:${GOTRUE_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@db:5432/postgres?sslmode=disable
      GOTRUE_LOG_LEVEL: debug  # Debug pour diagnostiquer probl√®mes
      GOTRUE_SITE_URL: ${SUPABASE_PUBLIC_URL}
      GOTRUE_URI_ALLOW_LIST: "*"
      GOTRUE_DISABLE_SIGNUP: false
      GOTRUE_JWT_SECRET: ${JWT_SECRET}
      GOTRUE_JWT_EXP: 3600
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'

  # Service REST (PostgREST) - MOT DE PASSE UNIFI√â
  rest:
    container_name: supabase-rest
    image: postgrest/postgrest:${POSTGREST_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      PGRST_DB_URI: postgres://postgres:${POSTGRES_PASSWORD}@db:5432/postgres
      PGRST_DB_SCHEMAS: public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: "false"
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'

  # Service Realtime - MOT DE PASSE UNIFI√â + CORRECTIONS ARM64 COMPL√àTES
  realtime:
    container_name: supabase-realtime
    image: supabase/realtime:${REALTIME_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      # CORRECTION INT√âGR√âE: Variables encryption Realtime (√©vite crypto_one_time error)
      DB_ENC_KEY: ${DB_ENC_KEY}
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      APP_NAME: supabase_realtime

      # Configuration DB (connexion PostgreSQL)
      DB_HOST: db
      DB_PORT: 5432
      DB_NAME: postgres
      DB_USER: postgres
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_SSL: disable
      DB_IP_VERSION: ipv4

      # Runtime Elixir (critique pour ARM64 d'apr√®s recherches)
      ERL_AFLAGS: "-proto_dist inet_tcp"
      DNS_NODES: ""
      SEED_SELF_HOST: "true"

      # Service config
      PORT: 4000
      API_JWT_SECRET: ${JWT_SECRET}

      # Performance Pi 5 (d'apr√®s recherches)
      DB_POOL_SIZE: 10
      MAX_CONNECTIONS: 16384
      RLIMIT_NOFILE: 65536
    ulimits:
      nofile:
        soft: 65536  # Optimis√© Pi 5 : 262144‚Üí65536
        hard: 65536
    cap_add:
      - SYS_RESOURCE  # Permet modification limites runtime
    sysctls:
      net.core.somaxconn: 65535  # Optimisation connexions WebSocket
    deploy:
      resources:
        limits:
          memory: 256MB  # Realtime WebSocket needs more
          cpus: '0.5'

  # Service Storage - MOT DE PASSE UNIFI√â
  storage:
    container_name: supabase-storage
    image: supabase/storage-api:${STORAGE_API_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      ANON_KEY: ${SUPABASE_ANON_KEY}
      SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      DATABASE_URL: postgres://postgres:${POSTGRES_PASSWORD}@db:5432/postgres
      FILE_SIZE_LIMIT: 52428800
      STORAGE_BACKEND: file
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:5001
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'
    volumes:
      - ./volumes/storage:/var/lib/storage:z

  # Service Meta (PostgREST Schema)
  meta:
    container_name: supabase-meta
    image: supabase/postgres-meta:${POSTGRES_META_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: db
      PG_META_DB_PORT: 5432
      PG_META_DB_NAME: postgres
      PG_META_DB_USER: postgres
      PG_META_DB_PASSWORD: ${POSTGRES_PASSWORD}
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'

  # Kong API Gateway - IMAGE ARM64 SP√âCIFIQUE POUR PI 5
  kong:
    container_name: supabase-kong
    image: arm64v8/kong:${KONG_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      auth:
        condition: service_started
      rest:
        condition: service_started
      realtime:
        condition: service_started
      storage:
        condition: service_started
      meta:
        condition: service_started
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /tmp/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_DNS_RESOLVER: "127.0.0.11:53"  # CRITIQUE: DNS interne Docker
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      # ARM64/Pi 5 specific optimizations
      KONG_NGINX_WORKER_PROCESSES: "2"
      KONG_MEM_CACHE_SIZE: "128m"
    ports:
      - "${SUPABASE_PORT}:8000"
    volumes:
      - ./volumes/kong/kong.yml:/tmp/kong.yml:ro  # Fichier final pr√©-rendu

  # Service Studio (Interface Web)
  studio:
    container_name: supabase-studio
    image: supabase/studio:${STUDIO_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    depends_on:
      kong:
        condition: service_started
    environment:
      STUDIO_PG_META_URL: http://meta:8080
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      DEFAULT_ORGANIZATION_NAME: "Pi 5 Supabase"
      DEFAULT_PROJECT_NAME: "Pi5 Project"
      SUPABASE_URL: http://kong:8000
      SUPABASE_REST_URL: http://kong:8000/rest/v1/
      SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SUPABASE_SERVICE_KEY}
      LOGFLARE_API_KEY: your-super-secret-and-long-logflare-key
      LOGFLARE_URL: http://analytics:4000
      NEXT_PUBLIC_ENABLE_LOGS: true
    ports:
      - "3000:3000"

  # Image Proxy pour transformations
  imgproxy:
    container_name: supabase-imgproxy
    image: darthsim/imgproxy:${IMGPROXY_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    environment:
      IMGPROXY_BIND: ":5001"
      IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"
      IMGPROXY_ENABLE_WEBP_DETECTION: "true"
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'
    volumes:
      - ./volumes/storage:/var/lib/storage:z

  # Edge Functions - CORRECTED 2025 FORMAT
  edge-functions:
    container_name: supabase-edge-functions
    image: supabase/edge-runtime:${EDGE_RUNTIME_VERSION}
    platform: linux/arm64
    restart: unless-stopped
    user: "1000:1000"  # CRITIQUE: √âviter permission denied
    command:
      - start
      - --main-service
      - /home/deno/functions/hello  # Corrig√©: utiliser 'hello' pas 'main'
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${SUPABASE_ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SUPABASE_SERVICE_KEY}
    volumes:
      - ./volumes/functions:/home/deno/functions:Z  # SELinux-safe mount
    ports:
      - "54321:9000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/_internal/health/liveness"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128MB  # Optimis√© Pi 5
          cpus: '0.5'

  # NOTE: supabase-vector D√âSACTIV√â pour Pi 5 ARM64
  # Cause des probl√®mes de page size sur ARM64
  # R√©activer uniquement si page size 4KB confirm√© fonctionnel

networks:
  default:
    name: supabase_network

COMPOSE

  chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/docker-compose.yml"

  # Validation syntaxe YAML (fail fast) avec logs d√©taill√©s
  log "üîç Validation syntaxe YAML docker-compose.yml..."

  # Log des variables critiques pour debug
  log "   Variables critiques :"
  log "     POSTGRES_VERSION=$POSTGRES_VERSION"
  log "     POSTGRES_PASSWORD length=${#POSTGRES_PASSWORD}"
  log "     JWT_SECRET length=${#JWT_SECRET}"
  log "     LOCAL_IP=$LOCAL_IP"

  # Test validation avec sortie d√©taill√©e
  local yaml_validation_output
  yaml_validation_output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose config" 2>&1)
  local yaml_exit_code=$?

  if [[ $yaml_exit_code -eq 0 ]]; then
    ok "‚úÖ docker-compose.yml syntaxe valid√©e ($(wc -l < "$PROJECT_DIR/docker-compose.yml") lignes)"
    log "   Services d√©tect√©s: $(echo "$yaml_validation_output" | grep -c "container_name:")"
  else
    error "‚ùå Erreur syntaxe dans docker-compose.yml (code: $yaml_exit_code)"
    log "   Erreur Docker Compose:"
    echo "$yaml_validation_output" | head -10
    log "   Contenu docker-compose (20 premi√®res lignes):"
    nl -ba "$PROJECT_DIR/docker-compose.yml" | sed -n '1,20p'
    log "   Variables .env (v√©rification):"
    head -5 "$PROJECT_DIR/.env"
    log ""
    log "   üìã Commandes debug manuelles :"
    log "   cd /home/pi/stacks/supabase"
    log "   docker compose config  # Voir erreur exacte"
    log "   head -30 docker-compose.yml  # V√©rifier syntaxe"
    log "   grep -n 'cpus:' docker-compose.yml  # Chercher guillemets mal ferm√©es"
    exit 1
  fi
}

create_kong_config() {
  log "‚öôÔ∏è Cr√©ation configuration Kong..."

  mkdir -p "$PROJECT_DIR/volumes/kong"
  cat > "$PROJECT_DIR/volumes/kong/kong.yml" << 'KONG'
_format_version: "1.1"

consumers:
  - username: anon
    keyauth_credentials:
      - key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJvbGUiOiJhbm9uIiwiaWF0IjoxNjQ1MTkwNzI0LCJleHAiOjE5NjA3NjY3MjR9.M9jrxyvPLkUxWgOYSf5dNdJ8v_eWrqwU7WgMaOFErDg
  - username: service_role
    keyauth_credentials:
      - key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJvbGUiOiJzZXJ2aWNlX3JvbGUiLCJpYXQiOjE2NDUxOTA3MjQsImV4cCI6MTk2MDc2NjcyNH0.T49KQx5LzLqbNBDOgdYlCW0Rf7cCUfz1bVy9q_Tl2X8

acls:
  - consumer: anon
    group: anon
  - consumer: service_role
    group: admin

services:
  - name: auth-v1-open
    url: http://auth:9999/
    routes:
      - name: auth-v1-open
        strip_path: true
        paths:
          - "/auth/v1/signup"
          - "/auth/v1/token"
          - "/auth/v1/verify"
          - "/auth/v1/callback"
          - "/auth/v1/authorize"
          - "/auth/v1/logout"
          - "/auth/v1/recover"
          - "/auth/v1/user"

  - name: auth-v1-open-invite
    url: http://auth:9999/
    routes:
      - name: auth-v1-open-invite
        strip_path: true
        paths:
          - "/auth/v1/invite"

  - name: auth-v1-open-otp
    url: http://auth:9999/
    routes:
      - name: auth-v1-open-otp
        strip_path: true
        paths:
          - "/auth/v1/otp"

  - name: rest-v1
    url: http://rest:3000/
    routes:
      - name: rest-v1-all
        strip_path: true
        paths:
          - "/rest/v1/"
    plugins:
      - name: cors
      - name: key-auth
        config:
          hide_credentials: false
      - name: acl
        config:
          hide_groups_header: true

  - name: realtime-v1
    url: http://realtime:4000/socket/
    routes:
      - name: realtime-v1
        strip_path: true
        paths:
          - "/realtime/v1/"
    plugins:
      - name: cors
      - name: key-auth
        config:
          hide_credentials: false
      - name: acl
        config:
          hide_groups_header: true

  - name: storage-v1
    url: http://storage:5000/
    routes:
      - name: storage-v1-all
        strip_path: true
        paths:
          - "/storage/v1/"
    plugins:
      - name: cors

  - name: edge-functions-v1
    url: http://edge-functions:9000/
    routes:
      - name: edge-functions-v1-all
        strip_path: true
        paths:
          - "/functions/v1/"
    plugins:
      - name: cors
KONG

  chown -R "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/volumes/kong"
  ok "‚úÖ Configuration Kong cr√©√©e"
}

render_kong_config() {
  log "üîß Pr√©-rendu configuration Kong avec variables..."

  # Installer envsubst si n√©cessaire
  if ! command -v envsubst >/dev/null 2>&1; then
    log "   Installation gettext-base pour envsubst..."
    apt-get update -qq && apt-get install -y gettext-base >/dev/null 2>&1
  fi

  # Pr√©-rendre le template Kong avec substitution des variables
  if envsubst < "$PROJECT_DIR/config/kong.tpl.yml" > "$PROJECT_DIR/volumes/kong/kong.yml"; then
    chown "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/volumes/kong/kong.yml"
    ok "‚úÖ Kong config pr√©-rendue ($(wc -l < "$PROJECT_DIR/volumes/kong/kong.yml") lignes)"
  else
    error "‚ùå Erreur pr√©-rendu Kong template"
    log "   üìã Debug Kong template :"
    log "   head -10 $PROJECT_DIR/config/kong.tpl.yml"
    log "   env | grep SUPABASE"
    exit 1
  fi
}

start_database_only() {
  log "üóÑÔ∏è D√©marrage PostgreSQL (cr√©ation structures)..."

  # CRITIQUE: Toujours se placer dans le bon r√©pertoire
  cd "$PROJECT_DIR" || { error "‚ùå Impossible d'acc√©der √† $PROJECT_DIR"; exit 1; }

  # Logs de debug pour l'environnement
  log "üîç Environnement Docker :"
  log "   R√©pertoire: $(pwd)"
  log "   Utilisateur: $TARGET_USER"
  log "   Docker running: $(systemctl is-active docker)"

  # T√©l√©charger et d√©marrer UNIQUEMENT la base de donn√©es
  log "üì¶ T√©l√©chargement image PostgreSQL..."
  docker compose pull db 2>/dev/null || warn "Pas de nouvelles images disponibles"

  log "üèóÔ∏è D√©marrage conteneur PostgreSQL seul..."
  docker compose up -d db

  echo ""
  echo "‚è≥ ATTENTE INITIALISATION POSTGRESQL (1-2 minutes)"
  echo "   Le script attend que PostgreSQL soit compl√®tement ready..."
  echo "   Ceci est normal et n√©cessaire pour cr√©er les structures database."
  echo ""

  # Attendre que PostgreSQL soit ready avec gestion d'erreur robuste
  # Tol√©rer des retours non-z√©ro pendant le wait
  set +e
  local max_attempts=30
  local attempt=0
  local pg_ready=false

  while [[ $attempt -lt $max_attempts ]] && [[ "$pg_ready" == "false" ]]; do
    ((attempt++))

    # V√©rifier d'abord que le conteneur tourne
    if ! docker ps --filter "name=supabase-db" --filter "status=running" | grep -q supabase-db; then
      printf "\r   ‚è±Ô∏è  Attente d√©marrage conteneur... %02d/%02d tentatives" $attempt $max_attempts
    else
      # Ensuite v√©rifier que PostgreSQL accepte les connexions (sans set -e)
      if docker exec supabase-db pg_isready -U postgres >/dev/null 2>&1; then
        pg_ready=true
        break
      else
        printf "\r   ‚è±Ô∏è  PostgreSQL initialisation... %02d/%02d tentatives (ne pas interrompre)" $attempt $max_attempts
      fi
    fi

    sleep 3
  done

  if [[ "$pg_ready" == "false" ]]; then
    echo ""
    error "‚ùå PostgreSQL ne d√©marre pas apr√®s $max_attempts tentatives ($((max_attempts * 3)) secondes)"
    echo ""
    echo "üìã Diagnostic PostgreSQL :"
    echo "   docker logs supabase-db --tail=10"
    echo "   docker exec supabase-db pg_isready -U postgres"
    echo "   docker ps --filter name=supabase-db"
    exit 1
  fi

  # R√©activer le mode strict
  set -e

  echo ""
  ok "‚úÖ PostgreSQL d√©marr√© et ready - cr√©ation des structures..."
}

start_remaining_services() {
  log "üöÄ D√©marrage services Supabase restants..."

  cd "$PROJECT_DIR" || { error "‚ùå Impossible d'acc√©der √† $PROJECT_DIR"; exit 1; }

  # Message d'attente clair pour le t√©l√©chargement d'images
  echo ""
  echo "‚è≥ T√âL√âCHARGEMENT DES IMAGES DOCKER (2-5 minutes selon connexion)"
  echo "   Le script t√©l√©charge les images Supabase depuis Docker Hub..."
  echo "   Images requises: Auth, Realtime, Storage, Kong, Studio (~ 1-2GB)"
  echo ""

  log "üì¶ T√©l√©chargement images restantes..."
  local pull_output pull_exit_code
  pull_output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose pull" 2>&1)
  pull_exit_code=$?

  if [[ $pull_exit_code -eq 0 ]]; then
    log "   Images t√©l√©charg√©es: $(echo "$pull_output" | grep -c "Pulled" || echo "0")"
    log "   Images √† jour: $(echo "$pull_output" | grep -c "up to date" || echo "0")"
    ok "‚úÖ T√©l√©chargement termin√©"
  else
    warn "‚ö†Ô∏è Erreur t√©l√©chargement images (continuons avec existantes)"
  fi

  # Message d'attente pour le d√©marrage des conteneurs
  echo ""
  echo "‚è≥ D√âMARRAGE DES CONTENEURS (1-2 minutes)"
  echo "   Le script d√©marre tous les services Supabase..."
  echo "   Services: Auth, Realtime, Storage, Kong, PostgREST, Studio"
  echo ""

  log "üèóÔ∏è D√©marrage services restants..."
  local up_output up_exit_code
  up_output=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d" 2>&1)
  up_exit_code=$?

  if [[ $up_exit_code -eq 0 ]]; then
    local containers_running=$(docker compose ps --services --filter status=running | wc -l)
    local containers_total=$(docker compose ps --services | wc -l)
    ok "‚úÖ Services lanc√©s ($containers_running/$containers_total actifs)"

    # Log status initial des conteneurs
    log "   Conteneurs cr√©√©s:"
    docker compose ps --format "table {{.Name}}\t{{.State}}" | head -5
  else
    error "‚ùå Erreur d√©marrage conteneurs (code: $up_exit_code)"
    log "   Sortie docker compose up:"
    echo "$up_output" | head -15
    exit 1
  fi
}

wait_for_services() {
  echo ""
  echo "‚è≥ ATTENTE INITIALISATION DES SERVICES (3-5 minutes)"
  echo "   Le script v√©rifie que tous les services Supabase sont pr√™ts..."
  echo "   Services surveill√©s: PostgreSQL, Auth, PostgREST, Realtime, Kong"
  echo "   NE PAS INTERROMPRE - La premi√®re initialisation peut prendre du temps"
  echo ""

  log "‚è≥ Attente initialisation des services..."
  cd "$PROJECT_DIR"

  # Tol√©rer des retours non-z√©ro pendant le wait
  set +e
  local max_attempts=30
  local attempt=0
  local services=("db" "auth" "rest" "realtime" "kong")

  # Log initial des conteneurs
  log "üîç √âtat initial des conteneurs :"
  docker compose ps --format "table {{.Name}}\t{{.State}}\t{{.Status}}" | head -6

  while [[ $attempt -lt $max_attempts ]]; do
    local healthy_count=0
    local service_status=""

    # Affichage du progr√®s avec printf (pas de nouvelle ligne)
    printf "\r   ‚è±Ô∏è  V√©rification services... %02d/%02d tentatives (temps √©coul√©: %d min)" $((attempt+1)) $max_attempts $((attempt*10/60))

    for service in "${services[@]}"; do
      local health_status=$(docker inspect --format='{{.State.Health.Status}}' supabase-${service} 2>/dev/null || echo "none")
      local running_status=$(docker inspect --format='{{.State.Status}}' supabase-${service} 2>/dev/null || echo "missing")

      # Crit√®res plus tol√©rants : running OU healthy
      if [[ "$health_status" == "healthy" ]] || [[ "$running_status" == "running" ]] || [[ "$service" == "db" && "$health_status" == "none" && "$running_status" == "running" ]]; then
        ((healthy_count++))
        service_status+=" ‚úÖ$service"
      else
        service_status+=" ‚ùå$service($running_status)"
        # Log d√©taill√© pour les services en √©chec
        if [[ $attempt -eq 5 ]] || [[ $attempt -eq 15 ]]; then  # Log √† 50s et 150s
          echo ""  # Nouvelle ligne pour les logs d√©taill√©s
          log "     Service $service : state=$running_status, health=$health_status"
          if [[ "$running_status" == "exited" ]]; then
            log "     Derni√®res logs $service :"
            docker compose logs --tail=3 "$service" 2>/dev/null | grep -v "^$" || true
          fi
        fi
      fi
    done

    # Accepter si au moins DB + 2 autres services fonctionnent
    if [[ $healthy_count -eq ${#services[@]} ]]; then
      echo ""  # Nouvelle ligne apr√®s printf
      ok "‚úÖ Tous les services sont op√©rationnels ($healthy_count/${#services[@]})"
      log "   Services: $service_status"
      # R√©activer le mode strict
      set -e
      return 0
    elif [[ $healthy_count -ge 3 ]] && [[ $attempt -gt 10 ]]; then
      echo ""  # Nouvelle ligne apr√®s printf
      ok "‚úÖ Services critiques op√©rationnels ($healthy_count/${#services[@]}) - Continue l'installation"
      log "   Services: $service_status"
      # R√©activer le mode strict
      set -e
      return 0
    fi

    # Log d√©taill√© toutes les 30s
    if [[ $attempt -eq 0 ]] || [[ $(($attempt % 3)) -eq 0 ]]; then
      echo ""  # Nouvelle ligne pour log d√©taill√©
      log "   √âtat services: $service_status"
    fi

    sleep 10
    ((attempt++))
  done

  echo ""  # Nouvelle ligne apr√®s printf
  warn "‚ö†Ô∏è TIMEOUT ATTEINT apr√®s $((max_attempts * 10))s - Certains services ne r√©pondent pas"
  log "   Services finaux: $service_status"
  echo ""
  echo "üîß QUE FAIRE EN CAS DE TIMEOUT :"
  echo ""
  echo "1Ô∏è‚É£ **V√©rifier l'√©tat des conteneurs** :"
  echo "   cd /home/pi/stacks/supabase"
  echo "   docker compose ps"
  echo ""
  echo "2Ô∏è‚É£ **Consulter les logs des services en √©chec** :"
  echo "   docker compose logs db --tail=20"
  echo "   docker compose logs realtime --tail=10"
  echo "   docker compose logs auth --tail=10"
  echo ""
  echo "3Ô∏è‚É£ **Relancer le script si n√©cessaire** :"
  echo "   cd $(dirname "${BASH_SOURCE[0]}")"
  echo "   sudo ./setup-week2-supabase-final.sh"
  echo ""
  echo "4Ô∏è‚É£ **Nettoyer si probl√®me persistant** :"
  echo "   sudo ./cleanup-week2-supabase.sh"
  echo ""
  echo "‚ö†Ô∏è  Le script continue avec les services disponibles..."
  echo "    Vous pourrez relancer pour corriger les services manquants."
  echo ""

  # R√©activer le mode strict
  set -e
}

create_complete_database_structure() {
  echo ""
  echo "üóÑÔ∏è CR√âATION STRUCTURES DATABASE COMPL√àTES"
  echo "   Cr√©ation de tous les sch√©mas, r√¥les et types PostgreSQL..."
  echo "   Cette √©tape √©vite les erreurs Auth/Realtime par la suite."
  echo ""

  cd "$PROJECT_DIR" || return 1

  # PostgreSQL devrait d√©j√† √™tre ready depuis start_database_only()
  # V√©rification rapide avec protection
  set +e
  if ! docker exec supabase-db pg_isready -U postgres >/dev/null 2>&1; then
    warn "‚ö†Ô∏è PostgreSQL non ready - attente suppl√©mentaire..."
    local attempt=0
    while [[ $attempt -lt 10 ]]; do
      ((attempt++))
      printf "\r   ‚è±Ô∏è  Attente PostgreSQL... %02d/10" $attempt
      if docker exec supabase-db pg_isready -U postgres >/dev/null 2>&1; then
        echo ""
        break
      fi
      sleep 2
    done
  fi
  set -e

  log "üîß Cr√©ation sch√©mas, r√¥les et structures critiques..."
  docker exec -T supabase-db psql -U postgres -d postgres -c "
    -- Cr√©er tous les sch√©mas n√©cessaires
    CREATE SCHEMA IF NOT EXISTS auth;
    CREATE SCHEMA IF NOT EXISTS realtime;
    CREATE SCHEMA IF NOT EXISTS storage;

    -- Cr√©er tous les r√¥les PostgreSQL
    DO \$\$ BEGIN
      IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'anon') THEN
        CREATE ROLE anon NOLOGIN;
        RAISE NOTICE 'R√¥le anon cr√©√©';
      END IF;

      IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'authenticated') THEN
        CREATE ROLE authenticated NOLOGIN;
        RAISE NOTICE 'R√¥le authenticated cr√©√©';
      END IF;

      IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'service_role') THEN
        CREATE ROLE service_role NOLOGIN;
        RAISE NOTICE 'R√¥le service_role cr√©√©';
      END IF;
    END \$\$;

    -- Types et structures critiques Auth
    DO \$\$ BEGIN
      IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'factor_type') THEN
        CREATE TYPE auth.factor_type AS ENUM ('totp', 'phone');
        RAISE NOTICE 'Type auth.factor_type cr√©√©';
      END IF;
    EXCEPTION
      WHEN duplicate_object THEN
        RAISE NOTICE 'Type auth.factor_type existe d√©j√†';
    END \$\$;

    -- Table schema_migrations Realtime avec structure Ecto correcte
    -- CRITICAL: Une seule cr√©ation, structure valid√©e pour Elixir/Ecto
    DROP TABLE IF EXISTS realtime.schema_migrations CASCADE;
    DROP TABLE IF EXISTS public.schema_migrations CASCADE;
    CREATE TABLE realtime.schema_migrations(
      version BIGINT NOT NULL PRIMARY KEY,
      inserted_at TIMESTAMP(0) WITHOUT TIME ZONE NOT NULL DEFAULT NOW()
    );

    -- Permissions sur tous les sch√©mas
    GRANT USAGE ON SCHEMA auth TO postgres, anon, authenticated, service_role;
    GRANT USAGE ON SCHEMA realtime TO postgres, anon, authenticated, service_role;
    GRANT USAGE ON SCHEMA storage TO postgres, anon, authenticated, service_role;

    RAISE NOTICE 'Structure database compl√®te cr√©√©e avec succ√®s';
  " 2>/dev/null || log "‚ö†Ô∏è Certaines structures existent d√©j√† (normal)"

  ok "‚úÖ Structure database compl√®te - sch√©mas, r√¥les, types cr√©√©s"
}

clean_corrupted_realtime_data() {
  if docker compose ps realtime 2>/dev/null | grep -q "Restarting"; then
    log "üßπ Nettoyage donn√©es Realtime corrompues d√©tect√©es..."

    docker compose stop realtime 2>/dev/null || true

    # Nettoyer donn√©es corrompues avec ancien JWT_SECRET
    docker exec -T supabase-db psql -U postgres -d postgres -c "
      DELETE FROM realtime.tenants WHERE jwt_secret IS NOT NULL;
      DELETE FROM realtime.extensions;
      RAISE NOTICE 'Donn√©es Realtime corrompues supprim√©es';
    " 2>/dev/null || log "‚ö†Ô∏è Tables Realtime pas encore cr√©√©es"

    sleep 2
    docker compose start realtime 2>/dev/null || true
    log "‚úÖ Realtime nettoy√© et red√©marr√© avec nouveau JWT_SECRET"
  fi
}

# =============================================================================
# CORRECTION TENANT REALTIME CORROMPU - INT√âGRATION COMPL√àTE
# Bas√© sur session de debugging 15/09/2025 - R√©solution tenant "realtime-dev"
# =============================================================================

fix_realtime_corrupted_tenant() {
  log "üßπ Nettoyage tenant Realtime corrompu (correction int√©gr√©e)..."

  # Supprimer tenant "realtime-dev" corrompu qui cause les erreurs de seeding
  # Cette correction √©vite l'erreur: crypto_one_time lors du seeding
  docker exec -T supabase-db psql -U postgres -d postgres -c "
    DELETE FROM _realtime.tenants WHERE external_id = 'realtime-dev';
    DELETE FROM realtime.tenants WHERE external_id = 'realtime-dev';
  " 2>/dev/null || log "   Table tenants pas encore cr√©√©e (normal en d√©but d'installation)"

  ok "‚úÖ Tenant Realtime corrompu nettoy√©"
}

fix_common_service_issues() {
  log "üîß Correction automatique probl√®mes courants des services..."
  cd "$PROJECT_DIR" || return 1

  # V√©rifier si des services red√©marrent en boucle
  local restarting_services
  restarting_services=$(docker compose ps --filter "status=restarting" --format "{{.Name}}" | grep -E "(auth|storage|realtime)" || true)

  if [[ -n "$restarting_services" ]]; then
    log "   Services en red√©marrage d√©tect√©s: $restarting_services"

    # Attendre que PostgreSQL soit accessible
    local max_attempts=15
    local attempt=0
    while ! docker exec supabase-db pg_isready -U postgres >/dev/null 2>&1; do
      ((attempt++))
      if [[ $attempt -ge $max_attempts ]]; then
        warn "PostgreSQL non accessible, abandon de la correction automatique"
        return 1
      fi
      log "   Attente PostgreSQL... ($attempt/$max_attempts)"
      sleep 2
    done

    # Nettoyer donn√©es Realtime corrompues si n√©cessaire
    clean_corrupted_realtime_data

    # CORRECTION INT√âGR√âE: Nettoyer tenant realtime-dev corrompu
    fix_realtime_corrupted_tenant

    # Correction 1: Cr√©er le sch√©ma auth, r√¥les et types manquants
    log "   Cr√©ation sch√©ma auth complet avec types et r√¥les..."
    docker exec supabase-db psql -U postgres -d postgres -c "
      DO \$\$
      BEGIN
          -- Cr√©er le sch√©ma auth
          CREATE SCHEMA IF NOT EXISTS auth;

          -- Cr√©er le type factor_type pour MFA (r√©sout l'erreur auth.factor_type does not exist)
          BEGIN
              CREATE TYPE auth.factor_type AS ENUM ('totp', 'phone');
              RAISE NOTICE 'auth.factor_type cr√©√© avec succ√®s';
          EXCEPTION
              WHEN duplicate_object THEN
                  RAISE NOTICE 'auth.factor_type existe d√©j√†';
          END;

          -- Cr√©er les r√¥les PostgreSQL
          IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'anon') THEN
              CREATE ROLE anon;
              GRANT USAGE ON SCHEMA public TO anon;
              GRANT USAGE ON SCHEMA auth TO anon;
          END IF;
          IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'service_role') THEN
              CREATE ROLE service_role;
              GRANT ALL ON SCHEMA public TO service_role;
              GRANT ALL ON SCHEMA auth TO service_role;
          END IF;
          IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = 'authenticated') THEN
              CREATE ROLE authenticated;
              GRANT USAGE ON SCHEMA public TO authenticated;
              GRANT USAGE ON SCHEMA auth TO authenticated;
          END IF;
      END
      \$\$;
    " 2>/dev/null || true

    # Correction 2: Cr√©er sch√©ma Realtime avec table schema_migrations correcte
    log "   Cr√©ation sch√©ma Realtime pour migrations..."
    docker exec supabase-db psql -U postgres -d postgres -c "
      -- Cr√©er le sch√©ma realtime
      CREATE SCHEMA IF NOT EXISTS realtime;

      -- Cr√©er la table schema_migrations avec version BIGINT (requis par Ecto)
      CREATE TABLE IF NOT EXISTS realtime.schema_migrations(
        version BIGINT PRIMARY KEY,
        inserted_at TIMESTAMP(0) WITHOUT TIME ZONE DEFAULT NOW()
      );

      -- Supprimer la table public.schema_migrations si elle existe pour √©viter la confusion
      DROP TABLE IF EXISTS public.schema_migrations;
    " 2>/dev/null || true

    # Correction 3: Ajouter variables manquantes pour Realtime
    local env_updated=false
    if ! grep -q "^APP_NAME=" .env 2>/dev/null; then
      echo "APP_NAME=supabase" >> .env
      env_updated=true
    fi
    if ! grep -q "^REALTIME_APP_NAME=" .env 2>/dev/null; then
      echo "REALTIME_APP_NAME=supabase" >> .env
      env_updated=true
    fi
    if ! grep -q "^REALTIME_DB_PASSWORD=" .env 2>/dev/null; then
      local postgres_password
      postgres_password=$(grep "^POSTGRES_PASSWORD=" .env | cut -d'=' -f2 | tr -d '"')
      echo "REALTIME_DB_PASSWORD=$postgres_password" >> .env
      env_updated=true
    fi

    if [[ "$env_updated" == "true" ]]; then
      log "   Variables d'environnement mises √† jour"

      echo ""
      echo "üîß RED√âMARRAGE SERVICES PROBL√âMATIQUES (30 secondes)"
      echo "   Arr√™t propre des services Auth, Storage, Realtime..."
      echo "   Puis red√©marrage avec nouvelles variables d'environnement"
      echo ""

      # Red√©marrer les services probl√©matiques
      log "   Arr√™t des services en √©chec..."
      docker compose stop auth storage realtime 2>/dev/null || true
      printf "   ‚è±Ô∏è  Attente arr√™t propre... 3 secondes"
      sleep 3
      echo ""

      log "   Red√©marrage avec nouvelles variables..."
      docker compose up -d auth storage realtime 2>/dev/null || true

      # Attendre un peu pour la stabilisation
      echo "   ‚è±Ô∏è  Stabilisation des services... 15 secondes (ne pas interrompre)"
      sleep 15
      ok "‚úÖ Correction automatique appliqu√©e"
    else
      ok "‚úÖ Variables d'environnement OK"
    fi
  else
    ok "‚úÖ Aucun service en red√©marrage d√©tect√©"
  fi
}

# =============================================================================
# NOUVELLES CORRECTIONS AUTH & REALTIME - INT√âGRATION SESSION DEBUGGING 15/09/2025
# Bas√© sur documentation DEBUG-SESSION-AUTH-MIGRATION.md et DEBUG-SESSION-REALTIME.md
# =============================================================================

fix_auth_uuid_operator_issue() {
  log "üîß Correction op√©rateur PostgreSQL uuid = text (Auth migration)..."
  cd "$PROJECT_DIR" || return 1

  # Test si l'erreur uuid = text existe
  local uuid_error
  uuid_error=$(docker exec supabase-db psql -U postgres -d postgres -tAc "
    SELECT id = user_id::text
    FROM auth.identities
    LIMIT 1;
  " 2>&1 || echo "Erreur uuid = text confirm√©e")

  if [[ "$uuid_error" == *"operator does not exist"* ]]; then
    log "   Erreur uuid = text d√©tect√©e - Cr√©ation op√©rateur PostgreSQL..."

    # Cr√©er op√©rateur uuid = text
    docker exec supabase-db psql -U postgres -d postgres -c "
      DO \$\$
      BEGIN
          -- Cr√©er fonction de comparaison uuid = text
          CREATE OR REPLACE FUNCTION uuid_text_eq(uuid, text)
          RETURNS boolean AS
          \$func\$
              SELECT \$1::text = \$2;
          \$func\$
          LANGUAGE SQL IMMUTABLE;

          -- Cr√©er op√©rateur = pour uuid, text
          IF NOT EXISTS (
              SELECT 1 FROM pg_operator
              WHERE oprname = '='
                AND oprleft = 'uuid'::regtype
                AND oprright = 'text'::regtype
          ) THEN
              CREATE OPERATOR = (
                  LEFTARG = uuid,
                  RIGHTARG = text,
                  FUNCTION = uuid_text_eq
              );
          END IF;
      END
      \$\$;
    " 2>/dev/null || true

    # Appliquer migration probl√©matique manuellement
    log "   Application migration 20221208132122 avec op√©rateur corrig√©..."
    docker exec supabase-db psql -U postgres -d postgres -c "
      UPDATE auth.identities
      SET last_sign_in_at = '2022-11-25'
      WHERE last_sign_in_at IS NULL
        AND created_at = '2022-11-25'
        AND updated_at = '2022-11-25'
        AND provider = 'email'
        AND id = user_id::text;
    " 2>/dev/null || true

    # Marquer migration comme ex√©cut√©e
    docker exec supabase-db psql -U postgres -d postgres -c "
      INSERT INTO auth.schema_migrations (version)
      VALUES ('20221208132122')
      ON CONFLICT (version) DO NOTHING;
    " 2>/dev/null || true

    ok "‚úÖ Op√©rateur uuid = text cr√©√© et migration corrig√©e"
  else
    ok "‚úÖ Op√©rateur uuid = text d√©j√† fonctionnel"
  fi
}

clean_env_duplicates() {
  log "üßπ Nettoyage doublons .env..."
  cd "$PROJECT_DIR" || return 1

  # CRITIQUE : Sauvegarder avant modification
  backup_env_file "$PROJECT_DIR/.env"

  # V√©rifier que le .env existe
  if [[ ! -f ".env" ]]; then
    error "‚ùå Fichier .env manquant avant nettoyage des doublons"
    restore_env_if_missing "$PROJECT_DIR/.env"
    return 1
  fi

  # Cr√©er fichier temporaire sans doublons
  local temp_env=$(mktemp)

  # Garder seulement la derni√®re occurrence de chaque variable
  awk -F'=' '!seen[$1]++ {vars[NR]=$0} seen[$1]==1 {vars[NR]=$0} END {for(i=1;i<=NR;i++) if(vars[i]) print vars[i]}' .env > "$temp_env"

  # Remplacer le fichier original seulement si le temp est valide
  if [[ -s "$temp_env" ]]; then
    mv "$temp_env" .env
    chown "$TARGET_USER:$TARGET_USER" .env
    chmod 600 .env

    # VALIDATION critique apr√®s modification
    if validate_env_file "$PROJECT_DIR/.env"; then
      ok "‚úÖ Doublons .env supprim√©s et fichier valid√©"
    else
      error "‚ùå .env corrompu apr√®s nettoyage, restauration..."
      restore_env_if_missing "$PROJECT_DIR/.env"
      return 1
    fi
  else
    error "‚ùå Fichier temporaire vide, annulation nettoyage"
    rm -f "$temp_env"
    return 1
  fi
}

validate_realtime_schema_migrations() {
  log "‚úÖ Validation table schema_migrations Realtime..."

  # V√©rifier que la table existe avec la bonne structure
  local table_exists
  table_exists=$(docker exec supabase-db psql -U postgres -d postgres -tAc "
    SELECT EXISTS (
      SELECT FROM information_schema.tables
      WHERE table_schema = 'realtime'
      AND table_name = 'schema_migrations'
    );
  " 2>/dev/null || echo "f")

  local has_correct_structure
  has_correct_structure=$(docker exec supabase-db psql -U postgres -d postgres -tAc "
    SELECT COUNT(*) = 2 FROM information_schema.columns
    WHERE table_schema = 'realtime'
    AND table_name = 'schema_migrations'
    AND column_name IN ('version', 'inserted_at')
    AND is_nullable = 'NO';
  " 2>/dev/null || echo "f")

  if [[ "$table_exists" == "t" && "$has_correct_structure" == "t" ]]; then
    ok "‚úÖ Table realtime.schema_migrations correctement structur√©e pour Ecto"

    # Log de la structure pour confirmation
    log "   Structure valid√©e:"
    docker exec supabase-db psql -U postgres -d postgres -c "\d realtime.schema_migrations;" 2>/dev/null | head -10
    return 0
  else
    error "‚ùå Table realtime.schema_migrations incorrecte ou manquante"
    log "   Table exists: $table_exists"
    log "   Correct structure: $has_correct_structure"
    return 1
  fi
}

validate_post_creation_environment() {
  log "üîç Validation compl√®te environment post-cr√©ation..."
  cd "$PROJECT_DIR" || return 1

  local validation_errors=0

  echo ""
  echo "=== VALIDATION ENVIRONNEMENT COMPLET ==="

  # 1. Validation fichier .env
  echo "1Ô∏è‚É£ Validation fichier .env:"
  if [[ -f ".env" ]]; then
    echo "   ‚úÖ Fichier .env pr√©sent"

    # V√©rifier variables critiques avec longueurs
    local critical_vars=("SUPABASE_PORT" "LOCAL_IP" "POSTGRES_PASSWORD" "JWT_SECRET" "DB_ENC_KEY" "SECRET_KEY_BASE")
    for var in "${critical_vars[@]}"; do
      if grep -q "^${var}=" .env 2>/dev/null; then
        local value=$(grep "^${var}=" .env | cut -d'=' -f2)
        local length=${#value}
        case "$var" in
          "DB_ENC_KEY")
            if [[ $length -eq 16 ]]; then
              echo "   ‚úÖ $var: $length chars (correct pour AES-128)"
            else
              echo "   ‚ùå $var: $length chars (attendu: 16)"
              ((validation_errors++))
            fi
            ;;
          "SECRET_KEY_BASE")
            if [[ $length -eq 64 ]]; then
              echo "   ‚úÖ $var: $length chars (correct pour Elixir)"
            else
              echo "   ‚ùå $var: $length chars (attendu: 64)"
              ((validation_errors++))
            fi
            ;;
          *)
            echo "   ‚úÖ $var: pr√©sent ($length chars)"
            ;;
        esac
      else
        echo "   ‚ùå $var: MANQUANT"
        ((validation_errors++))
      fi
    done
  else
    echo "   ‚ùå Fichier .env MANQUANT"
    ((validation_errors++))
  fi

  # 2. Validation structure base de donn√©es
  echo ""
  echo "2Ô∏è‚É£ Validation structure base de donn√©es:"
  if docker exec supabase-db pg_isready -U postgres >/dev/null 2>&1; then
    echo "   ‚úÖ PostgreSQL accessible"

    # V√©rifier sch√©mas
    local schemas=$(docker exec supabase-db psql -U postgres -d postgres -tAc "SELECT string_agg(schema_name, ',') FROM information_schema.schemata WHERE schema_name IN ('auth','realtime','storage');" 2>/dev/null)
    if [[ "$schemas" == *"auth"* && "$schemas" == *"realtime"* && "$schemas" == *"storage"* ]]; then
      echo "   ‚úÖ Sch√©mas critiques pr√©sents: $schemas"
    else
      echo "   ‚ùå Sch√©mas manquants. Pr√©sents: $schemas"
      ((validation_errors++))
    fi

    # V√©rifier table schema_migrations
    local table_check=$(docker exec supabase-db psql -U postgres -d postgres -tAc "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema = 'realtime' AND table_name = 'schema_migrations');" 2>/dev/null)
    if [[ "$table_check" == "t" ]]; then
      echo "   ‚úÖ Table realtime.schema_migrations pr√©sente"
    else
      echo "   ‚ùå Table realtime.schema_migrations MANQUANTE"
      ((validation_errors++))
    fi
  else
    echo "   ‚ùå PostgreSQL non accessible"
    ((validation_errors++))
  fi

  # 3. Validation Docker Compose
  echo ""
  echo "3Ô∏è‚É£ Validation Docker Compose:"
  if docker compose config >/dev/null 2>&1; then
    echo "   ‚úÖ Configuration Docker Compose valide"
  else
    echo "   ‚ùå Configuration Docker Compose INVALIDE"
    docker compose config 2>&1 | head -5 | sed 's/^/      /'
    ((validation_errors++))
  fi

  # 4. R√©sum√© validation
  echo ""
  echo "=== R√âSUM√â VALIDATION ==="
  if [[ $validation_errors -eq 0 ]]; then
    ok "‚úÖ Validation compl√®te r√©ussie - Environment pr√™t pour Realtime"
    return 0
  else
    error "‚ùå Validation √©chou√©e avec $validation_errors erreur(s)"
    log "   üîß Corrections n√©cessaires avant d√©marrage services"
    return 1
  fi
}

fix_realtime_encryption_variables() {
  log "üîê V√©rification variables encryption Realtime..."
  cd "$PROJECT_DIR" || return 1

  # PROTECTION : V√©rifier .env avant modification
  if ! restore_env_if_missing "$PROJECT_DIR/.env"; then
    error "‚ùå Impossible de restaurer .env manquant"
    return 1
  fi

  # Sauvegarder avant modifications
  backup_env_file "$PROJECT_DIR/.env"

  local env_updated=false

  # V√©rifier DB_ENC_KEY (16 caract√®res pour AES-128)
  if ! grep -q "^DB_ENC_KEY=" .env 2>/dev/null; then
    local db_enc_key
    db_enc_key=$(openssl rand -hex 8)  # 16 caract√®res hex
    echo "DB_ENC_KEY=$db_enc_key" >> .env
    env_updated=true
    log "   DB_ENC_KEY g√©n√©r√©: $db_enc_key (16 chars)"
  fi

  # V√©rifier SECRET_KEY_BASE (64 caract√®res pour Elixir)
  if ! grep -q "^SECRET_KEY_BASE=" .env 2>/dev/null; then
    local secret_key_base
    secret_key_base=$(openssl rand -hex 32)  # 64 caract√®res hex
    echo "SECRET_KEY_BASE=$secret_key_base" >> .env
    env_updated=true
    log "   SECRET_KEY_BASE g√©n√©r√©: ${secret_key_base:0:16}... (64 chars)"
  fi

  # V√©rifier APP_NAME pour Realtime
  if ! grep -q "^APP_NAME=" .env 2>/dev/null; then
    echo "APP_NAME=supabase_realtime" >> .env
    env_updated=true
  fi

  # Nettoyer doublons apr√®s ajouts
  if [[ "$env_updated" == "true" ]]; then
    clean_env_duplicates || {
      error "‚ùå √âchec nettoyage doublons"
      return 1
    }

    # VALIDATION critique apr√®s modifications
    if validate_env_file "$PROJECT_DIR/.env"; then
      log "   Variables encryption mises √† jour - red√©marrage Realtime..."
      docker compose restart realtime 2>/dev/null || true
      sleep 10
      ok "‚úÖ Variables encryption configur√©es et Realtime red√©marr√©"
    else
      error "‚ùå .env corrompu apr√®s ajout variables Realtime"
      restore_env_if_missing "$PROJECT_DIR/.env"
      return 1
    fi
  else
    ok "‚úÖ Variables encryption d√©j√† pr√©sentes"
  fi
}

fix_docker_compose_yaml_indentation() {
  log "üîß V√©rification indentation docker-compose.yml (√©viter corruption YAML)..."
  cd "$PROJECT_DIR" || return 1

  # V√©rifier syntaxe YAML actuelle
  if ! docker compose config > /dev/null 2>&1; then
    warn "‚ö†Ô∏è YAML corrompu d√©tect√© - tentative de correction..."

    # Corriger indentation APP_NAME incorrecte (8 espaces ‚Üí 6 espaces)
    if grep -q "^        APP_NAME:" docker-compose.yml; then
      log "   Correction indentation APP_NAME (8 ‚Üí 6 espaces)..."
      sed -i 's/^        APP_NAME:/      APP_NAME:/' docker-compose.yml
    fi

    # V√©rifier correction
    if docker compose config > /dev/null 2>&1; then
      ok "‚úÖ Indentation YAML corrig√©e"
    else
      warn "‚ö†Ô∏è Probl√®me YAML persiste - v√©rification manuelle requise"
      return 1
    fi
  else
    ok "‚úÖ Syntaxe YAML correcte"
  fi
}

validate_auth_realtime_fixes() {
  log "üß™ Validation corrections Auth & Realtime..."
  cd "$PROJECT_DIR" || return 1

  # Test Auth - op√©rateur uuid = text
  local auth_test
  auth_test=$(docker exec supabase-db psql -U postgres -d postgres -tAc "
    SELECT 'uuid_operator_test' as test,
           EXISTS(SELECT 1 FROM pg_operator
                  WHERE oprname = '='
                    AND oprleft = 'uuid'::regtype
                    AND oprright = 'text'::regtype) as exists;
  " 2>/dev/null || echo "error")

  if [[ "$auth_test" == *"t"* ]]; then
    ok "‚úÖ Auth: Op√©rateur uuid = text fonctionnel"
  else
    warn "‚ö†Ô∏è Auth: Op√©rateur uuid = text manquant"
  fi

  # Test Realtime - variables encryption
  local realtime_vars
  realtime_vars=$(docker exec supabase-realtime env 2>/dev/null | grep -E "DB_ENC_KEY|SECRET_KEY_BASE|APP_NAME" | wc -l || echo "0")

  if [[ "${realtime_vars:-0}" -ge 3 ]] 2>/dev/null; then
    ok "‚úÖ Realtime: Variables encryption pr√©sentes"
  else
    warn "‚ö†Ô∏è Realtime: Variables encryption manquantes ou conteneur non accessible"
  fi

  # Test statut services
  local auth_status realtime_status
  auth_status=$(docker ps --filter "name=supabase-auth" --format "{{.Status}}" | head -1)
  realtime_status=$(docker ps --filter "name=supabase-realtime" --format "{{.Status}}" | head -1)

  if echo "$auth_status" | grep -q "Up"; then
    ok "‚úÖ Auth service stable"
  else
    warn "‚ö†Ô∏è Auth service instable: $auth_status"
  fi

  if echo "$realtime_status" | grep -q "Up"; then
    ok "‚úÖ Realtime service stable"
  else
    warn "‚ö†Ô∏è Realtime service instable: $realtime_status"
  fi
}

create_database_users() {
  log "üë• Cr√©ation utilisateurs PostgreSQL avec mots de passe unifi√©s..."

  # S'assurer d'√™tre dans le bon r√©pertoire
  cd "$PROJECT_DIR" || { error "‚ùå Impossible d'acc√©der √† $PROJECT_DIR"; exit 1; }

  # **SOLUTION FINALE: Un seul mot de passe pour √©viter les erreurs auth**
  # Tous les utilisateurs utilisent POSTGRES_PASSWORD

  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T db psql -U postgres << 'SQL'
-- Cr√©er tous les utilisateurs avec POSTGRES_PASSWORD unifi√©
DO \$\$
BEGIN
  -- service_role (CRITIQUE pour Auth/RLS)
  IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'service_role') THEN
    CREATE USER service_role WITH BYPASSRLS CREATEDB PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Created service_role user';
  ELSE
    ALTER USER service_role WITH PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Updated service_role password';
  END IF;

  -- authenticator (pour Rest service)
  IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'authenticator') THEN
    CREATE USER authenticator WITH NOINHERIT LOGIN PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Created authenticator user';
  ELSE
    ALTER USER authenticator WITH PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Updated authenticator password';
  END IF;

  -- anon (utilisateur anonyme)
  IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'anon') THEN
    CREATE USER anon;
    RAISE NOTICE 'Created anon user';
  END IF;

  -- supabase_storage_admin (pour Storage service)
  IF NOT EXISTS (SELECT 1 FROM pg_roles WHERE rolname = 'supabase_storage_admin') THEN
    CREATE USER supabase_storage_admin WITH CREATEDB PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Created supabase_storage_admin user';
  ELSE
    ALTER USER supabase_storage_admin WITH PASSWORD '$POSTGRES_PASSWORD';
    RAISE NOTICE 'Updated supabase_storage_admin password';
  END IF;
END
\$\$;

-- Permissions essentielles
GRANT USAGE ON SCHEMA public TO anon, service_role;
GRANT CREATE ON SCHEMA public TO service_role;

-- Permissions pour authenticator (lier les r√¥les)
GRANT anon TO authenticator;
GRANT service_role TO authenticator;

-- Permissions √©tendues
GRANT ALL PRIVILEGES ON DATABASE postgres TO service_role, supabase_storage_admin;
GRANT ALL PRIVILEGES ON SCHEMA public TO service_role;

-- Extensions n√©cessaires pour Supabase
CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";
CREATE EXTENSION IF NOT EXISTS \"pgcrypto\";
CREATE EXTENSION IF NOT EXISTS \"pg_stat_statements\";

SELECT 'Utilisateurs cr√©√©s avec mots de passe unifi√©s' as result;
\q
SQL" 2>/dev/null

  if [[ $? -eq 0 ]]; then
    ok "‚úÖ Utilisateurs PostgreSQL cr√©√©s avec mots de passe unifi√©s"
  else
    warn "‚ö†Ô∏è Erreur cr√©ation utilisateurs - Services peuvent red√©marrer"
  fi
}

restart_dependent_services() {
  echo ""
  echo "üîÑ RED√âMARRAGE FINAL DES SERVICES (30 secondes)"
  echo "   Red√©marrage Auth, PostgREST, Storage, Realtime avec nouveaux utilisateurs..."
  echo "   Cette √©tape finale assure que tous les services utilisent les bonnes credentials"
  echo ""

  log "üîÑ Red√©marrage services d√©pendants avec nouveaux utilisateurs..."

  # S'assurer d'√™tre dans le bon r√©pertoire
  cd "$PROJECT_DIR" || { error "‚ùå Impossible d'acc√©der √† $PROJECT_DIR"; exit 1; }

  # Red√©marrer les services qui utilisent les nouveaux utilisateurs
  log "   Red√©marrage Auth, PostgREST, Storage, Realtime..."
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart auth rest storage realtime"

  # Attendre stabilisation finale (m√©thode simple et robuste)
  echo "   ‚è±Ô∏è  Attente stabilisation finale... 30 secondes (derni√®re √©tape)"
  echo "   Services en cours de red√©marrage avec nouvelles credentials..."

  # Simple sleep sans boucle complexe pour √©viter interruptions
  sleep 30

  echo "   ‚úÖ Stabilisation termin√©e"

  ok "‚úÖ Services red√©marr√©s et stabilis√©s"

  # V√©rification finale de l'√©tat des services apr√®s red√©marrage
  echo ""
  echo "üìã √âTAT FINAL DES SERVICES :"
  docker compose ps --format "table {{.Name}}\t{{.State}}\t{{.Status}}" | head -10
}

create_utility_scripts() {
  log "üõ†Ô∏è Cr√©ation scripts utilitaires..."

  # Script de sant√©
  cat > "$PROJECT_DIR/scripts/supabase-health.sh" << 'HEALTH'
#!/bin/bash
cd "$(dirname "$0")/.."

echo "=== √âtat Supabase ==="
docker compose ps

echo ""
echo "=== Tests connectivit√© ==="

# Test Studio
if curl -s -m 5 http://localhost:3000 >/dev/null; then
  echo "‚úÖ Studio OK"
else
  echo "‚ùå Studio KO"
fi

# Test API
if curl -s -m 5 "http://localhost:$(grep SUPABASE_PORT .env | cut -d= -f2)" >/dev/null; then
  echo "‚úÖ API OK"
else
  echo "‚ùå API KO"
fi

# Test PostgreSQL
if docker compose exec -T db psql -U postgres -c "SELECT 1;" >/dev/null 2>&1; then
  echo "‚úÖ PostgreSQL OK"
else
  echo "‚ùå PostgreSQL KO"
fi
HEALTH

  # Script de logs
  cat > "$PROJECT_DIR/scripts/supabase-logs.sh" << 'LOGS'
#!/bin/bash
cd "$(dirname "$0")/.."

if [[ -n "$1" ]]; then
  docker compose logs -f "$1"
else
  echo "Usage: $0 <service>"
  echo "Services disponibles:"
  docker compose ps --services
fi
LOGS

  # Script de red√©marrage
  cat > "$PROJECT_DIR/scripts/supabase-restart.sh" << 'RESTART'
#!/bin/bash
cd "$(dirname "$0")/.."

echo "üîÑ Red√©marrage s√©curis√© Supabase..."

# PROTECTION : Sauvegarder .env avant toute op√©ration
if [[ -f .env ]]; then
  cp .env ".env.bak.restart.$(date +%Y%m%d_%H%M%S)"
  echo "üíæ Sauvegarde .env effectu√©e"
else
  echo "‚ùå ERREUR : Fichier .env manquant, arr√™t"
  exit 1
fi

# Utiliser 'stop' au lieu de 'down' pour pr√©server la configuration
echo "‚èπÔ∏è  Arr√™t des services..."
docker compose stop
sleep 5

# V√©rifier que .env existe toujours
if [[ ! -f .env ]]; then
  echo "‚ö†Ô∏è  .env manquant apr√®s arr√™t, restauration..."
  latest_backup=$(ls -1t .env.bak.restart.* 2>/dev/null | head -1)
  if [[ -n "$latest_backup" ]]; then
    cp "$latest_backup" .env
    echo "‚úÖ .env restaur√©"
  else
    echo "‚ùå Impossible de restaurer .env"
    exit 1
  fi
fi

echo "üöÄ Red√©marrage des services..."
docker compose up -d
echo "‚úÖ Red√©marrage termin√©"
RESTART

  # Script de sauvegarde
  cat > "$PROJECT_DIR/scripts/supabase-backup.sh" << 'BACKUP'
#!/bin/bash
cd "$(dirname "$0")/.."

BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "üîÑ Sauvegarde Supabase en cours..."

# Sauvegarde base de donn√©es
if docker compose exec -T db pg_dump -U postgres -d postgres --clean > "$BACKUP_DIR/db.dump.sql" 2>/dev/null; then
  echo "‚úÖ Base de donn√©es sauvegard√©e"
else
  echo "‚ùå Erreur sauvegarde base de donn√©es"
fi

# Sauvegarde configuration
tar -czf "$BACKUP_DIR/config.tar.gz" .env docker-compose.yml config/ 2>/dev/null
echo "‚úÖ Configuration sauvegard√©e"

# Informations syst√®me
echo "=== Info Sauvegarde ===" > "$BACKUP_DIR/info.txt"
date >> "$BACKUP_DIR/info.txt"
docker compose ps >> "$BACKUP_DIR/info.txt"
echo "‚úÖ Sauvegarde termin√©e dans $BACKUP_DIR"
BACKUP

  # Script de monitoring
  cat > "$PROJECT_DIR/scripts/supabase-monitor.sh" << 'MONITOR'
#!/bin/bash
cd "$(dirname "$0")/.."

echo "=== Monitoring Supabase Pi 5 ==="
echo "Temps: $(date)"
echo ""

echo "=== Ressources Syst√®me ==="
echo "RAM: $(free -h | grep Mem | awk '{print $3"/"$2}')"
echo "Disque: $(df -h / | tail -1 | awk '{print $3"/"$2" ("$5")"}')"
echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)% utilis√©"
echo ""

echo "=== Conteneurs Docker ==="
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}" | head -8

echo ""
echo "=== Services Supabase ==="
docker compose ps --format "table {{.Name}}\t{{.State}}\t{{.Status}}"

echo ""
echo "=== Logs r√©cents (erreurs) ==="
docker compose logs --tail=5 2>/dev/null | grep -i error | tail -3 || echo "Aucune erreur r√©cente"
MONITOR

  chmod +x "$PROJECT_DIR/scripts"/*.sh
  chown -R "$TARGET_USER:$TARGET_USER" "$PROJECT_DIR/scripts"

  ok "‚úÖ Scripts utilitaires cr√©√©s"
}

validate_installation() {
  log "üß™ Validation installation..."

  cd "$PROJECT_DIR"

  local tests_total=4
  local tests_passed=0

  log "Services actifs: $(su "$TARGET_USER" -c "docker compose ps --services --filter status=running" | wc -l)/$(su "$TARGET_USER" -c "docker compose ps --services" | wc -l)"

  # Test Studio
  if timeout 10 curl -s "http://localhost:3000" >/dev/null 2>&1; then
    ok "  ‚úÖ Studio accessible (port 3000)"
    ((tests_passed++))
  else
    warn "  ‚ùå Studio non accessible"
  fi

  # Test API Gateway
  if timeout 10 curl -s "http://localhost:$SUPABASE_PORT" >/dev/null 2>&1; then
    ok "  ‚úÖ API Gateway accessible (port $SUPABASE_PORT)"
    ((tests_passed++))
  else
    warn "  ‚ùå API Gateway non accessible"
  fi

  # Test PostgreSQL
  if su "$TARGET_USER" -c "docker compose exec -T db psql -U postgres -c 'SELECT 1;'" >/dev/null 2>&1; then
    ok "  ‚úÖ PostgreSQL accessible (port 5432)"
    ((tests_passed++))
  else
    warn "  ‚ùå PostgreSQL non accessible"
  fi

  # Test variables dans Auth (avec retry et fallback)
  local var_test_ok=false
  local retry_count=0

  while [[ $retry_count -lt 3 ]] && [[ $var_test_ok == false ]]; do
    if su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T auth printenv 2>/dev/null | grep -q 'API_EXTERNAL_URL'" 2>/dev/null; then
      var_test_ok=true
    else
      sleep 2
      ((retry_count++))
    fi
  done

  if [[ $var_test_ok == true ]]; then
    ok "  ‚úÖ Variables propag√©es correctement"
    ((tests_passed++))
  else
    # Test alternatif avec le fichier .env
    if [[ -f "$PROJECT_DIR/.env" ]] && grep -q "API_EXTERNAL_URL" "$PROJECT_DIR/.env" 2>/dev/null; then
      ok "  ‚úÖ Variables pr√©sentes dans .env (conteneur peut red√©marrer)"
      ((tests_passed++))
    else
      warn "  ‚ùå Probl√®me propagation variables"
    fi
  fi

  log "Tests r√©ussis: $tests_passed/$tests_total"

  if [[ $tests_passed -ge 3 ]]; then
    ok "‚úÖ Installation valid√©e avec succ√®s"
    return 0
  else
    warn "‚ö†Ô∏è Installation partiellement fonctionnelle"
    return 1
  fi
}

show_completion_summary() {
  echo ""
  echo "==================== üéâ SUPABASE Pi 5 INSTALL√â ! ===================="
  echo ""

  local validation_result=0
  validate_installation || validation_result=$?

  if [[ $validation_result -eq 0 ]]; then
    echo "‚úÖ **Installation finale r√©ussie avec tous les correctifs int√©gr√©s**"
  else
    echo "‚ö†Ô∏è **Installation termin√©e avec quelques points d'attention**"
  fi

  echo "   üéØ Page size: 4KB"
  echo "   üîß Mots de passe unifi√©s (plus d'erreurs auth)"
  echo "   ü•ß Optimis√© pour Pi 5 16GB ARM64"
  echo "   üîß Realtime: RLIMIT_NOFILE + ulimits (recherche 2024)"
  echo "   üîß Kong: ARM64 image + DNS resolver optimis√©"
  echo "   üîß Edge Functions: main function + command array correct"
  echo "   üîß Entropie syst√®me am√©lior√©e (haveged)"
  echo "   üîß Docker daemon: limits optimis√©es pour ARM64"
  echo ""
  echo "üìç **Acc√®s aux services** :"
  echo "   üé® Studio      : http://$LOCAL_IP:3000"
  echo "   üîå API Gateway : http://$LOCAL_IP:$SUPABASE_PORT"
  echo "   ‚ö° Edge Funcs  : http://$LOCAL_IP:54321/functions/v1/"
  echo "   üóÑÔ∏è PostgreSQL : localhost:5432"
  echo ""
  echo "üîë **Credentials sauv√©es dans** : $PROJECT_DIR/.env"
  echo ""
  echo "üõ†Ô∏è **Scripts de maintenance** :"
  echo "   cd $PROJECT_DIR"
  echo "   ./scripts/supabase-health.sh     # üè• V√©rifier sant√©"
  echo "   ./scripts/supabase-restart.sh    # üîÑ Red√©marrer"
  echo "   ./scripts/supabase-logs.sh <service>  # üìã Voir logs"
  echo ""
  echo "üìÇ **Logs** : $LOG_FILE"
  echo ""
  echo "üìã **Prochaine √©tape : Week 3 - HTTPS et acc√®s externe**"
  echo "=================================================================="
}

fix_realtime_ulimits() {
  log "‚ö° Correction post-install Realtime ulimits (RLIMIT_NOFILE)..."

  # S'assurer d'√™tre dans le bon r√©pertoire
  cd "$PROJECT_DIR"

  # 1. Tester ulimits actuelles
  log "   Test ulimits Realtime..."
  local ulimit_result=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T realtime sh -c 'ulimit -n' 2>/dev/null" || echo "error")

  if [[ "$ulimit_result" == "65536" ]]; then
    ok "‚úÖ Realtime ulimits d√©j√† correctes: $ulimit_result"
    return 0
  fi

  warn "‚ö†Ô∏è Realtime ulimits probl√©matiques: $ulimit_result"

  # 1.5. V√©rifier si warning cgroup memory pr√©sent
  log "   V√©rification warnings cgroup memory..."
  local cgroup_warnings=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose logs realtime 2>/dev/null | grep -c 'memory limit capabilities' || echo '0'" | head -1 | tr -d '\n')

  if [[ "${cgroup_warnings:-0}" -gt 0 ]] 2>/dev/null; then
    log "   ‚ö†Ô∏è Warnings cgroup memory d√©tect√©s ($cgroup_warnings)"
    log "   ‚ÑπÔ∏è Normal sur kernel 6.12 - fonctionnement non impact√©"
  fi

  # 2. Force restart Realtime (parfois suffisant)
  log "   Force restart Realtime..."
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose restart realtime" 2>/dev/null || true
  sleep 10

  # Re-test apr√®s restart
  ulimit_result=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T realtime sh -c 'ulimit -n' 2>/dev/null" || echo "error")
  if [[ "$ulimit_result" == "65536" ]]; then
    ok "‚úÖ Realtime ulimits corrig√©es apr√®s restart: $ulimit_result"
    return 0
  fi

  # 3. Force recreation si restart insuffisant
  log "   Force recreation Realtime (dernier recours)..."
  su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose up -d --force-recreate realtime" 2>/dev/null || true
  sleep 15

  # Test final
  ulimit_result=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T realtime sh -c 'ulimit -n' 2>/dev/null" || echo "error")
  if [[ "$ulimit_result" == "65536" ]]; then
    ok "‚úÖ Realtime ulimits corrig√©es apr√®s recreation: $ulimit_result"
  else
    warn "‚ö†Ô∏è Realtime ulimits persistantes: $ulimit_result"
    log "   V√©rifier /etc/systemd/system/docker.service.d/override.conf"
    log "   Peut n√©cessiter red√©marrage syst√®me pour effect complet"
  fi
}

validate_critical_services() {
  log "üîç Validation services critiques post-recherche..."

  cd "$PROJECT_DIR"
  local validation_errors=0

  # 0. V√©rifier kernel version et warnings cgroup memory
  local kernel_version=$(uname -r | cut -d. -f1-2)
  if [[ "$kernel_version" == "6.12" ]]; then
    log "   ‚ÑπÔ∏è Kernel 6.12 d√©tect√© - warnings cgroup memory attendus"
    local cgroup_warnings=$(docker compose logs 2>/dev/null | grep -c "memory limit capabilities" || echo "0" | head -1 | tr -d '\n')
    if [[ "${cgroup_warnings:-0}" -gt 0 ]] 2>/dev/null; then
      log "   ‚ö†Ô∏è $cgroup_warnings warnings cgroup memory trouv√©s (normal kernel 6.12)"
      log "   ‚úÖ Supabase fonctionne correctement malgr√© ces warnings"
    fi
  fi

  # 0.5. Validation cgroups selon recherche Gemini/GPT/Grok
  log "   Diagnostic cgroups complet..."
  local cgroup_controllers=""
  if [[ -f "/sys/fs/cgroup/cgroup.controllers" ]]; then
    cgroup_controllers=$(cat /sys/fs/cgroup/cgroup.controllers)
    if [[ "$cgroup_controllers" =~ memory ]]; then
      ok "  ‚úÖ Contr√¥leur cgroup memory disponible"
    else
      warn "  ‚ö†Ô∏è Contr√¥leur cgroup memory manquant: $cgroup_controllers"
      log "     V√©rifier /boot/firmware/cmdline.txt et red√©marrer"
    fi
  else
    warn "  ‚ö†Ô∏è Syst√®me cgroup v2 non d√©tect√©"
  fi

  # V√©rifier configuration Docker
  local docker_info_cgroup=$(docker info 2>/dev/null | grep -i 'Cgroup' || echo "non d√©tect√©")
  log "  üìä Docker cgroup info: $docker_info_cgroup"

  # 1. Valider Realtime (RLIMIT_NOFILE + ulimits)
  log "   V√©rification Realtime (RLIMIT_NOFILE)..."
  local realtime_ulimit=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T realtime sh -c 'ulimit -n' 2>/dev/null" || echo "error")

  if [[ "$realtime_ulimit" =~ ^(262144|65536)$ ]]; then
    ok "  ‚úÖ Realtime: ulimits configur√©s correctement ($realtime_ulimit)"
  else
    warn "  ‚ö†Ô∏è Realtime: ulimits probl√©matiques ($realtime_ulimit)"
    ((validation_errors++))

    # V√©rifications suppl√©mentaires selon recherche Gemini/GPT/Grok
    log "     Diagnostic ulimits √©tendu..."
    log "     - Docker daemon.json: $(test -f /etc/docker/daemon.json && echo "‚úÖ" || echo "‚ùå")"
    log "     - Docker service override: $(test -f /etc/systemd/system/docker.service.d/override.conf && echo "‚úÖ" || echo "‚ùå")"
    log "     - Variable RLIMIT_NOFILE container: $(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose exec -T realtime printenv RLIMIT_NOFILE 2>/dev/null" || echo "non d√©finie")"
  fi

  # 2. Valider Kong (ARM64 image + DNS)
  log "   V√©rification Kong (ARM64 + DNS)..."
  local kong_image=$(su "$TARGET_USER" -c "cd '$PROJECT_DIR' && docker compose ps kong --format json" 2>/dev/null | jq -r '.Image' 2>/dev/null || echo "unknown")
  if [[ "$kong_image" == *"arm64v8/kong"* ]]; then
    ok "  ‚úÖ Kong: image ARM64 sp√©cifique utilis√©e"
  else
    warn "  ‚ö†Ô∏è Kong: image ARM64 non d√©tect√©e: $kong_image"
    ((validation_errors++))
  fi

  # 3. Valider Edge Functions (hello function existe)
  log "   V√©rification Edge Functions (hello function)..."
  if [[ -f "$PROJECT_DIR/volumes/functions/hello/index.ts" ]]; then
    ok "  ‚úÖ Edge Functions: fonction hello cr√©√©e"
  else
    warn "  ‚ö†Ô∏è Edge Functions: fonction hello manquante"
    ((validation_errors++))
  fi

  # 4. V√©rifier entropie syst√®me finale
  log "   V√©rification entropie syst√®me..."
  local entropy=$(cat /proc/sys/kernel/random/entropy_avail 2>/dev/null || echo "0")
  if [[ $entropy -gt 1000 ]]; then
    ok "  ‚úÖ Entropie syst√®me: $entropy"
  else
    warn "  ‚ö†Ô∏è Entropie syst√®me faible: $entropy"
    ((validation_errors++))
  fi

  if [[ $validation_errors -eq 0 ]]; then
    ok "‚úÖ Tous les correctifs de recherche appliqu√©s avec succ√®s"
  else
    warn "‚ö†Ô∏è $validation_errors probl√®me(s) d√©tect√©(s) - v√©rifier logs"
  fi

  return $validation_errors
}

diagnose_realtime_issue() {
  echo ""
  echo "üîß DIAGNOSTIC REALTIME D√âTAILL√â"
  echo "   Investigation du probl√®me de red√©marrage..."
  echo ""

  cd "$PROJECT_DIR" || return 1

  # 1. V√©rifier les logs r√©cents
  echo "üìã Logs Realtime (20 derni√®res lignes) :"
  docker compose logs realtime --tail=20 2>/dev/null | tail -10

  # 2. V√©rifier les variables d'environnement critiques
  echo ""
  echo "üîç Variables d'environnement Realtime :"
  if docker compose ps | grep -q "realtime.*Up"; then
    docker compose exec realtime env 2>/dev/null | grep -E "(APP_NAME|ERL_AFLAGS|DB_|JWT)" | head -5
  else
    echo "   ‚ö†Ô∏è Conteneur Realtime non accessible pour inspection env"
  fi

  # 3. Test de connexion PostgreSQL depuis Realtime
  echo ""
  echo "üóÑÔ∏è Test connexion PostgreSQL :"
  local pg_test=$(docker compose exec realtime pg_isready -h db -p 5432 -U postgres 2>/dev/null || echo "FAILED")
  echo "   PostgreSQL depuis Realtime: $pg_test"

  # 4. Recommandations
  echo ""
  echo "üéØ Actions recommand√©es pour fixer Realtime :"
  echo "   1. V√©rifier JWT_SECRET (pas de multi-lignes)"
  echo "   2. Ajouter APP_NAME=supabase_realtime"
  echo "   3. Ajouter ERL_AFLAGS=-proto_dist inet_tcp"
  echo "   4. Nettoyer donn√©es corrompues realtime.schema_migrations"
  echo ""
}

finalize_installation() {
  echo ""
  echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
  echo "üéâ INSTALLATION SUPABASE TERMIN√âE AVEC SUCC√àS"
  echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
  echo ""

  # D√©tecter IP locale pour les URLs
  local local_ip
  local_ip=$(hostname -I | awk '{print $1}')

  echo "üåê **ACC√àS SUPABASE** :"
  echo "   üìä Studio (Interface Web)  : http://$local_ip:3000"
  echo "   üîå API REST Gateway        : http://$local_ip:8001"
  echo "   üóÑÔ∏è  PostgreSQL Direct      : $local_ip:5432"
  echo ""

  echo "üìã **V√âRIFICATION SERVICES** :"
  cd "$PROJECT_DIR" || return 1
  docker compose ps --format "table {{.Name}}\t{{.State}}\t{{.Status}}" | head -10

  # Diagnostic Realtime si probl√®me d√©tect√©
  if docker compose ps | grep -q "realtime.*Restarting"; then
    diagnose_realtime_issue
  fi

  echo ""

  echo "üõ†Ô∏è **COMMANDES UTILES** :"
  echo "   cd /home/pi/stacks/supabase"
  echo "   docker compose ps                    # √âtat des services"
  echo "   docker compose logs auth --tail=20   # Logs Auth"
  echo "   docker compose logs realtime --tail=20 # Logs Realtime"
  echo "   docker compose restart auth          # Red√©marrer Auth"
  echo ""

  echo "üìö **PROCHAINES √âTAPES** :"
  echo "   1Ô∏è‚É£ Ouvrir Studio : http://$local_ip:3000"
  echo "   2Ô∏è‚É£ Cr√©er un nouveau projet dans Studio"
  echo "   3Ô∏è‚É£ Noter les cl√©s API (anon_key, service_key)"
  echo "   4Ô∏è‚É£ Tester l'API REST : http://$local_ip:8001/rest/v1/"
  echo ""
  echo "üéØ Installation Pi 5 Supabase Self-Hosted compl√®te !"
  echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
}

validate_post_install_critical() {
  log "üß™ Validation critique post-installation..."

  local all_good=true
  local issues=()

  # 1. CRITIQUE : V√©rifier .env pr√©sent et valide
  if validate_env_file "$PROJECT_DIR/.env"; then
    ok "‚úÖ Fichier .env pr√©sent et complet"
  else
    all_good=false
    issues+=("Fichier .env manquant ou invalide")
  fi

  # 2. CRITIQUE : Kong sur port correct
  local kong_port
  kong_port=$(docker port supabase-kong 2>/dev/null | grep "8000/tcp" | cut -d: -f2)

  if [[ -n "$kong_port" && "$kong_port" == "8001" ]]; then
    ok "‚úÖ Kong accessible sur port configur√© : $kong_port"

    # Test API Supabase accessible
    if curl -sf "http://localhost:8001" >/dev/null 2>&1; then
      ok "‚úÖ API Supabase accessible sur http://localhost:8001"
    else
      all_good=false
      issues+=("API Supabase inaccessible sur port 8001")
    fi
  else
    all_good=false
    if [[ -n "$kong_port" ]]; then
      issues+=("Kong sur mauvais port : $kong_port (attendu: 8001)")
    else
      issues+=("Kong non accessible ou port ind√©termin√©")
    fi
  fi

  # 3. BLOQUANT : Services sans restart loop
  local restarting_services
  restarting_services=$(docker ps --filter "status=restarting" --format "{{.Names}}" | grep "supabase-" || true)

  if [[ -z "$restarting_services" ]]; then
    ok "‚úÖ Aucun service en restart loop"
  else
    all_good=false
    issues+=("Services en restart loop : $restarting_services")
  fi

  # 4. MAJEUR : Services unhealthy
  local unhealthy_services
  unhealthy_services=$(docker ps --filter "health=unhealthy" --format "{{.Names}}" | grep "supabase-" || true)

  if [[ -z "$unhealthy_services" ]]; then
    ok "‚úÖ Tous les services avec health check sont healthy"
  else
    warn "‚ö†Ô∏è Services unhealthy d√©tect√©s : $unhealthy_services"
  fi

  # 5. FONCTIONNEL : Studio accessible
  if curl -sf "http://localhost:3000" >/dev/null 2>&1; then
    ok "‚úÖ Studio Supabase accessible sur http://localhost:3000"
  else
    warn "‚ö†Ô∏è Studio Supabase non accessible (peut n√©cessiter quelques minutes de plus)"
  fi

  # R√©sum√© final
  if [[ "$all_good" == "true" ]]; then
    ok "üéâ VALIDATION R√âUSSIE - Toutes les v√©rifications critiques pass√©es"
    return 0
  else
    error "‚ùå VALIDATION √âCHOU√âE - Probl√®mes critiques d√©tect√©s :"
    for issue in "${issues[@]}"; do
      echo "   - $issue"
    done

    echo ""
    echo "üîß Actions correctives sugg√©r√©es :"
    echo "   1. Restaurer .env : restore_env_if_missing '$PROJECT_DIR/.env'"
    echo "   2. Red√©marrer Kong : docker compose restart kong"
    echo "   3. V√©rifier logs : docker compose logs --tail=20"
    echo "   4. Ex√©cuter diagnostic : ./scripts/supabase-diagnose.sh"

    return 1
  fi
}

main() {
  require_root
  setup_logging
  check_dependencies

  log "üéØ Installation pour utilisateur: $TARGET_USER"

  check_prerequisites
  optimize_system_for_supabase
  check_port_conflicts
  ensure_working_directory  # NOUVEAU: √âviter getcwd errors
  create_project_structure
  generate_secure_secrets    # NOUVEAU: JWT_SECRET s√©curis√© single-line
  create_env_file
  create_docker_compose
  create_kong_config
  render_kong_config  # NOUVEAU: Pr√©-render Kong template

  # NOUVEAU: D√©marrer DB SEULE d'abord pour cr√©er structures
  start_database_only
  create_complete_database_structure  # NOUVEAU: Structures compl√®tes AVANT services

  # D√©marrer le reste des services avec structures pr√™tes
  start_remaining_services
  wait_for_services
  fix_common_service_issues  # AM√âLIOR√â: + nettoyage donn√©es corrompues

  # NOUVELLES CORRECTIONS SESSION DEBUGGING 15/09/2025
  fix_auth_uuid_operator_issue      # Correction erreur uuid = text Auth migration
  fix_realtime_encryption_variables # Correction cl√©s encryption Realtime + nettoyage doublons
  fix_docker_compose_yaml_indentation # Pr√©vention corruption YAML
  validate_auth_realtime_fixes      # Validation corrections appliqu√©es

  # VALIDATION VERSION 2.4 - STRUCTURES ET VALIDATION
  validate_realtime_schema_migrations  # Validation table schema_migrations pour Ecto
  validate_post_creation_environment   # NOUVEAU: Validation compl√®te post-cr√©ation

  create_database_users
  restart_dependent_services
  fix_realtime_ulimits     # NOUVEAU: Correction post-install Realtime
  create_utility_scripts
  validate_critical_services

  # VALIDATION FINALE CRITIQUE - VERSION 2.4
  validate_post_install_critical

  show_completion_summary

  # NOUVEAU: Finalisation claire de l'installation
  finalize_installation
}

main "$@"